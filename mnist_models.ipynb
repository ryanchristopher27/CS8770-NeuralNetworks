{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include our Python packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get MNIST Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "train_dataset = MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=50, shuffle=True)\n",
    "\n",
    "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=50, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, D_out):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(D_in, H1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(H1, H2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(H2, D_out),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        y_pred = self.layers(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Nerual Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Model and Define HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MLP(\n",
    "#     D_in = 28*28,\n",
    "#     H1 = 28*28,\n",
    "#     H2 = 128,\n",
    "#     D_out = 10,\n",
    "# )\n",
    "model = CNN()\n",
    "\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "momentum = 0.3\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "status_interval = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "train_count = []\n",
    "test_loss = []\n",
    "test_count = [i*len(train_loader.dataset) for i in range(epochs + 1)]\n",
    "\n",
    "def train(epoch, dataloader, optimizer):\n",
    "    model.train()\n",
    "    for batch, (data, label) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "\n",
    "        loss = F.nll_loss(output, label)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % status_interval == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch * len(data)}/{len(dataloader.dataset)}] ({batch * 100 / len(dataloader):.0f}%)\\tLoss: {loss.item():.6f}')\n",
    "            train_loss.append(loss.item())\n",
    "            train_count.append((batch*64) + ((epoch-1)*len(dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, label in dataloader:\n",
    "            output = model(data)\n",
    "            loss += F.nll_loss(output, label, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(label.data.view_as(pred)).sum()\n",
    "    loss /= len(dataloader.dataset)\n",
    "    test_loss.append(loss)\n",
    "    print(f'\\nTest Set: Avg. Loss: {loss:.4f}, Accuracy: {correct}/{len(dataloader.dataset)} ({100 * correct / len(dataloader.dataset):.0f}%)\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rdash\\AppData\\Local\\Temp\\ipykernel_10888\\3801493435.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000] (0%)\tLoss: 0.552445\n",
      "Train Epoch: 1 [500/60000] (1%)\tLoss: 0.300014\n",
      "Train Epoch: 1 [1000/60000] (2%)\tLoss: 0.314469\n",
      "Train Epoch: 1 [1500/60000] (2%)\tLoss: 0.465116\n",
      "Train Epoch: 1 [2000/60000] (3%)\tLoss: 0.478122\n",
      "Train Epoch: 1 [2500/60000] (4%)\tLoss: 0.406605\n",
      "Train Epoch: 1 [3000/60000] (5%)\tLoss: 0.312628\n",
      "Train Epoch: 1 [3500/60000] (6%)\tLoss: 0.409932\n",
      "Train Epoch: 1 [4000/60000] (7%)\tLoss: 0.342909\n",
      "Train Epoch: 1 [4500/60000] (8%)\tLoss: 0.649409\n",
      "Train Epoch: 1 [5000/60000] (8%)\tLoss: 0.420100\n",
      "Train Epoch: 1 [5500/60000] (9%)\tLoss: 0.199654\n",
      "Train Epoch: 1 [6000/60000] (10%)\tLoss: 0.197089\n",
      "Train Epoch: 1 [6500/60000] (11%)\tLoss: 0.215835\n",
      "Train Epoch: 1 [7000/60000] (12%)\tLoss: 0.412043\n",
      "Train Epoch: 1 [7500/60000] (12%)\tLoss: 0.392234\n",
      "Train Epoch: 1 [8000/60000] (13%)\tLoss: 0.333468\n",
      "Train Epoch: 1 [8500/60000] (14%)\tLoss: 0.192518\n",
      "Train Epoch: 1 [9000/60000] (15%)\tLoss: 0.334776\n",
      "Train Epoch: 1 [9500/60000] (16%)\tLoss: 0.387263\n",
      "Train Epoch: 1 [10000/60000] (17%)\tLoss: 0.316960\n",
      "Train Epoch: 1 [10500/60000] (18%)\tLoss: 0.470778\n",
      "Train Epoch: 1 [11000/60000] (18%)\tLoss: 0.261622\n",
      "Train Epoch: 1 [11500/60000] (19%)\tLoss: 0.398378\n",
      "Train Epoch: 1 [12000/60000] (20%)\tLoss: 0.187000\n",
      "Train Epoch: 1 [12500/60000] (21%)\tLoss: 0.463755\n",
      "Train Epoch: 1 [13000/60000] (22%)\tLoss: 0.499667\n",
      "Train Epoch: 1 [13500/60000] (22%)\tLoss: 0.200555\n",
      "Train Epoch: 1 [14000/60000] (23%)\tLoss: 0.284997\n",
      "Train Epoch: 1 [14500/60000] (24%)\tLoss: 0.420157\n",
      "Train Epoch: 1 [15000/60000] (25%)\tLoss: 0.313327\n",
      "Train Epoch: 1 [15500/60000] (26%)\tLoss: 0.374360\n",
      "Train Epoch: 1 [16000/60000] (27%)\tLoss: 0.450755\n",
      "Train Epoch: 1 [16500/60000] (28%)\tLoss: 0.337550\n",
      "Train Epoch: 1 [17000/60000] (28%)\tLoss: 0.254875\n",
      "Train Epoch: 1 [17500/60000] (29%)\tLoss: 0.410845\n",
      "Train Epoch: 1 [18000/60000] (30%)\tLoss: 0.336007\n",
      "Train Epoch: 1 [18500/60000] (31%)\tLoss: 0.394351\n",
      "Train Epoch: 1 [19000/60000] (32%)\tLoss: 0.317231\n",
      "Train Epoch: 1 [19500/60000] (32%)\tLoss: 0.261308\n",
      "Train Epoch: 1 [20000/60000] (33%)\tLoss: 0.440453\n",
      "Train Epoch: 1 [20500/60000] (34%)\tLoss: 0.275818\n",
      "Train Epoch: 1 [21000/60000] (35%)\tLoss: 0.392647\n",
      "Train Epoch: 1 [21500/60000] (36%)\tLoss: 0.294127\n",
      "Train Epoch: 1 [22000/60000] (37%)\tLoss: 0.275030\n",
      "Train Epoch: 1 [22500/60000] (38%)\tLoss: 0.127294\n",
      "Train Epoch: 1 [23000/60000] (38%)\tLoss: 0.252968\n",
      "Train Epoch: 1 [23500/60000] (39%)\tLoss: 0.353893\n",
      "Train Epoch: 1 [24000/60000] (40%)\tLoss: 0.162146\n",
      "Train Epoch: 1 [24500/60000] (41%)\tLoss: 0.292439\n",
      "Train Epoch: 1 [25000/60000] (42%)\tLoss: 0.348014\n",
      "Train Epoch: 1 [25500/60000] (42%)\tLoss: 0.380441\n",
      "Train Epoch: 1 [26000/60000] (43%)\tLoss: 0.377692\n",
      "Train Epoch: 1 [26500/60000] (44%)\tLoss: 0.439799\n",
      "Train Epoch: 1 [27000/60000] (45%)\tLoss: 0.379102\n",
      "Train Epoch: 1 [27500/60000] (46%)\tLoss: 0.241678\n",
      "Train Epoch: 1 [28000/60000] (47%)\tLoss: 0.173487\n",
      "Train Epoch: 1 [28500/60000] (48%)\tLoss: 0.273013\n",
      "Train Epoch: 1 [29000/60000] (48%)\tLoss: 0.368282\n",
      "Train Epoch: 1 [29500/60000] (49%)\tLoss: 0.271940\n",
      "Train Epoch: 1 [30000/60000] (50%)\tLoss: 0.359838\n",
      "Train Epoch: 1 [30500/60000] (51%)\tLoss: 0.473041\n",
      "Train Epoch: 1 [31000/60000] (52%)\tLoss: 0.327930\n",
      "Train Epoch: 1 [31500/60000] (52%)\tLoss: 0.255500\n",
      "Train Epoch: 1 [32000/60000] (53%)\tLoss: 0.313612\n",
      "Train Epoch: 1 [32500/60000] (54%)\tLoss: 0.177342\n",
      "Train Epoch: 1 [33000/60000] (55%)\tLoss: 0.370263\n",
      "Train Epoch: 1 [33500/60000] (56%)\tLoss: 0.401414\n",
      "Train Epoch: 1 [34000/60000] (57%)\tLoss: 0.392609\n",
      "Train Epoch: 1 [34500/60000] (58%)\tLoss: 0.184485\n",
      "Train Epoch: 1 [35000/60000] (58%)\tLoss: 0.554599\n",
      "Train Epoch: 1 [35500/60000] (59%)\tLoss: 0.219608\n",
      "Train Epoch: 1 [36000/60000] (60%)\tLoss: 0.307078\n",
      "Train Epoch: 1 [36500/60000] (61%)\tLoss: 0.343321\n",
      "Train Epoch: 1 [37000/60000] (62%)\tLoss: 0.650893\n",
      "Train Epoch: 1 [37500/60000] (62%)\tLoss: 0.516347\n",
      "Train Epoch: 1 [38000/60000] (63%)\tLoss: 0.378347\n",
      "Train Epoch: 1 [38500/60000] (64%)\tLoss: 0.345486\n",
      "Train Epoch: 1 [39000/60000] (65%)\tLoss: 0.279786\n",
      "Train Epoch: 1 [39500/60000] (66%)\tLoss: 0.252349\n",
      "Train Epoch: 1 [40000/60000] (67%)\tLoss: 0.608146\n",
      "Train Epoch: 1 [40500/60000] (68%)\tLoss: 0.478440\n",
      "Train Epoch: 1 [41000/60000] (68%)\tLoss: 0.338280\n",
      "Train Epoch: 1 [41500/60000] (69%)\tLoss: 0.247393\n",
      "Train Epoch: 1 [42000/60000] (70%)\tLoss: 0.252336\n",
      "Train Epoch: 1 [42500/60000] (71%)\tLoss: 0.598280\n",
      "Train Epoch: 1 [43000/60000] (72%)\tLoss: 0.375770\n",
      "Train Epoch: 1 [43500/60000] (72%)\tLoss: 0.205896\n",
      "Train Epoch: 1 [44000/60000] (73%)\tLoss: 0.388989\n",
      "Train Epoch: 1 [44500/60000] (74%)\tLoss: 0.177234\n",
      "Train Epoch: 1 [45000/60000] (75%)\tLoss: 0.206357\n",
      "Train Epoch: 1 [45500/60000] (76%)\tLoss: 0.755799\n",
      "Train Epoch: 1 [46000/60000] (77%)\tLoss: 0.218699\n",
      "Train Epoch: 1 [46500/60000] (78%)\tLoss: 0.297370\n",
      "Train Epoch: 1 [47000/60000] (78%)\tLoss: 0.273475\n",
      "Train Epoch: 1 [47500/60000] (79%)\tLoss: 0.206183\n",
      "Train Epoch: 1 [48000/60000] (80%)\tLoss: 0.328113\n",
      "Train Epoch: 1 [48500/60000] (81%)\tLoss: 0.245167\n",
      "Train Epoch: 1 [49000/60000] (82%)\tLoss: 0.504096\n",
      "Train Epoch: 1 [49500/60000] (82%)\tLoss: 0.472207\n",
      "Train Epoch: 1 [50000/60000] (83%)\tLoss: 0.314166\n",
      "Train Epoch: 1 [50500/60000] (84%)\tLoss: 0.118338\n",
      "Train Epoch: 1 [51000/60000] (85%)\tLoss: 0.282515\n",
      "Train Epoch: 1 [51500/60000] (86%)\tLoss: 0.309574\n",
      "Train Epoch: 1 [52000/60000] (87%)\tLoss: 0.328615\n",
      "Train Epoch: 1 [52500/60000] (88%)\tLoss: 0.572316\n",
      "Train Epoch: 1 [53000/60000] (88%)\tLoss: 0.349525\n",
      "Train Epoch: 1 [53500/60000] (89%)\tLoss: 0.294773\n",
      "Train Epoch: 1 [54000/60000] (90%)\tLoss: 0.296507\n",
      "Train Epoch: 1 [54500/60000] (91%)\tLoss: 0.509101\n",
      "Train Epoch: 1 [55000/60000] (92%)\tLoss: 0.333726\n",
      "Train Epoch: 1 [55500/60000] (92%)\tLoss: 0.271238\n",
      "Train Epoch: 1 [56000/60000] (93%)\tLoss: 0.287603\n",
      "Train Epoch: 1 [56500/60000] (94%)\tLoss: 0.338183\n",
      "Train Epoch: 1 [57000/60000] (95%)\tLoss: 0.240163\n",
      "Train Epoch: 1 [57500/60000] (96%)\tLoss: 0.526448\n",
      "Train Epoch: 1 [58000/60000] (97%)\tLoss: 0.230517\n",
      "Train Epoch: 1 [58500/60000] (98%)\tLoss: 0.253518\n",
      "Train Epoch: 1 [59000/60000] (98%)\tLoss: 0.266398\n",
      "Train Epoch: 1 [59500/60000] (99%)\tLoss: 0.463556\n",
      "\n",
      "Test Set: Avg. Loss: 0.1350, Accuracy: 9574/10000 (96%)\n",
      "\n",
      "Train Epoch: 2 [0/60000] (0%)\tLoss: 0.241138\n",
      "Train Epoch: 2 [500/60000] (1%)\tLoss: 0.244493\n",
      "Train Epoch: 2 [1000/60000] (2%)\tLoss: 0.407428\n",
      "Train Epoch: 2 [1500/60000] (2%)\tLoss: 0.339128\n",
      "Train Epoch: 2 [2000/60000] (3%)\tLoss: 0.663087\n",
      "Train Epoch: 2 [2500/60000] (4%)\tLoss: 0.196588\n",
      "Train Epoch: 2 [3000/60000] (5%)\tLoss: 0.338628\n",
      "Train Epoch: 2 [3500/60000] (6%)\tLoss: 0.414798\n",
      "Train Epoch: 2 [4000/60000] (7%)\tLoss: 0.357136\n",
      "Train Epoch: 2 [4500/60000] (8%)\tLoss: 0.284532\n",
      "Train Epoch: 2 [5000/60000] (8%)\tLoss: 0.284246\n",
      "Train Epoch: 2 [5500/60000] (9%)\tLoss: 0.234780\n",
      "Train Epoch: 2 [6000/60000] (10%)\tLoss: 0.150120\n",
      "Train Epoch: 2 [6500/60000] (11%)\tLoss: 0.387310\n",
      "Train Epoch: 2 [7000/60000] (12%)\tLoss: 0.481450\n",
      "Train Epoch: 2 [7500/60000] (12%)\tLoss: 0.177471\n",
      "Train Epoch: 2 [8000/60000] (13%)\tLoss: 0.349948\n",
      "Train Epoch: 2 [8500/60000] (14%)\tLoss: 0.515518\n",
      "Train Epoch: 2 [9000/60000] (15%)\tLoss: 0.343481\n",
      "Train Epoch: 2 [9500/60000] (16%)\tLoss: 0.404562\n",
      "Train Epoch: 2 [10000/60000] (17%)\tLoss: 0.295870\n",
      "Train Epoch: 2 [10500/60000] (18%)\tLoss: 0.185289\n",
      "Train Epoch: 2 [11000/60000] (18%)\tLoss: 0.469261\n",
      "Train Epoch: 2 [11500/60000] (19%)\tLoss: 0.286089\n",
      "Train Epoch: 2 [12000/60000] (20%)\tLoss: 0.167859\n",
      "Train Epoch: 2 [12500/60000] (21%)\tLoss: 0.341251\n",
      "Train Epoch: 2 [13000/60000] (22%)\tLoss: 0.321115\n",
      "Train Epoch: 2 [13500/60000] (22%)\tLoss: 0.372292\n",
      "Train Epoch: 2 [14000/60000] (23%)\tLoss: 0.310356\n",
      "Train Epoch: 2 [14500/60000] (24%)\tLoss: 0.294046\n",
      "Train Epoch: 2 [15000/60000] (25%)\tLoss: 0.363514\n",
      "Train Epoch: 2 [15500/60000] (26%)\tLoss: 0.312407\n",
      "Train Epoch: 2 [16000/60000] (27%)\tLoss: 0.568034\n",
      "Train Epoch: 2 [16500/60000] (28%)\tLoss: 0.304450\n",
      "Train Epoch: 2 [17000/60000] (28%)\tLoss: 0.170623\n",
      "Train Epoch: 2 [17500/60000] (29%)\tLoss: 0.219308\n",
      "Train Epoch: 2 [18000/60000] (30%)\tLoss: 0.306812\n",
      "Train Epoch: 2 [18500/60000] (31%)\tLoss: 0.345045\n",
      "Train Epoch: 2 [19000/60000] (32%)\tLoss: 0.268017\n",
      "Train Epoch: 2 [19500/60000] (32%)\tLoss: 0.342152\n",
      "Train Epoch: 2 [20000/60000] (33%)\tLoss: 0.561036\n",
      "Train Epoch: 2 [20500/60000] (34%)\tLoss: 0.288557\n",
      "Train Epoch: 2 [21000/60000] (35%)\tLoss: 0.490565\n",
      "Train Epoch: 2 [21500/60000] (36%)\tLoss: 0.259623\n",
      "Train Epoch: 2 [22000/60000] (37%)\tLoss: 0.227204\n",
      "Train Epoch: 2 [22500/60000] (38%)\tLoss: 0.131549\n",
      "Train Epoch: 2 [23000/60000] (38%)\tLoss: 0.185013\n",
      "Train Epoch: 2 [23500/60000] (39%)\tLoss: 0.299587\n",
      "Train Epoch: 2 [24000/60000] (40%)\tLoss: 0.208778\n",
      "Train Epoch: 2 [24500/60000] (41%)\tLoss: 0.232954\n",
      "Train Epoch: 2 [25000/60000] (42%)\tLoss: 0.450294\n",
      "Train Epoch: 2 [25500/60000] (42%)\tLoss: 0.213668\n",
      "Train Epoch: 2 [26000/60000] (43%)\tLoss: 0.483641\n",
      "Train Epoch: 2 [26500/60000] (44%)\tLoss: 0.307092\n",
      "Train Epoch: 2 [27000/60000] (45%)\tLoss: 0.614655\n",
      "Train Epoch: 2 [27500/60000] (46%)\tLoss: 0.348793\n",
      "Train Epoch: 2 [28000/60000] (47%)\tLoss: 0.287091\n",
      "Train Epoch: 2 [28500/60000] (48%)\tLoss: 0.425634\n",
      "Train Epoch: 2 [29000/60000] (48%)\tLoss: 0.284794\n",
      "Train Epoch: 2 [29500/60000] (49%)\tLoss: 0.492285\n",
      "Train Epoch: 2 [30000/60000] (50%)\tLoss: 0.301501\n",
      "Train Epoch: 2 [30500/60000] (51%)\tLoss: 0.321276\n",
      "Train Epoch: 2 [31000/60000] (52%)\tLoss: 0.572685\n",
      "Train Epoch: 2 [31500/60000] (52%)\tLoss: 0.552168\n",
      "Train Epoch: 2 [32000/60000] (53%)\tLoss: 0.285706\n",
      "Train Epoch: 2 [32500/60000] (54%)\tLoss: 0.283863\n",
      "Train Epoch: 2 [33000/60000] (55%)\tLoss: 0.217547\n",
      "Train Epoch: 2 [33500/60000] (56%)\tLoss: 0.163315\n",
      "Train Epoch: 2 [34000/60000] (57%)\tLoss: 0.227627\n",
      "Train Epoch: 2 [34500/60000] (58%)\tLoss: 0.231421\n",
      "Train Epoch: 2 [35000/60000] (58%)\tLoss: 0.395913\n",
      "Train Epoch: 2 [35500/60000] (59%)\tLoss: 0.265593\n",
      "Train Epoch: 2 [36000/60000] (60%)\tLoss: 0.223312\n",
      "Train Epoch: 2 [36500/60000] (61%)\tLoss: 0.178224\n",
      "Train Epoch: 2 [37000/60000] (62%)\tLoss: 0.295316\n",
      "Train Epoch: 2 [37500/60000] (62%)\tLoss: 0.352116\n",
      "Train Epoch: 2 [38000/60000] (63%)\tLoss: 0.233365\n",
      "Train Epoch: 2 [38500/60000] (64%)\tLoss: 0.270849\n",
      "Train Epoch: 2 [39000/60000] (65%)\tLoss: 0.367550\n",
      "Train Epoch: 2 [39500/60000] (66%)\tLoss: 0.588539\n",
      "Train Epoch: 2 [40000/60000] (67%)\tLoss: 0.349049\n",
      "Train Epoch: 2 [40500/60000] (68%)\tLoss: 0.309697\n",
      "Train Epoch: 2 [41000/60000] (68%)\tLoss: 0.720606\n",
      "Train Epoch: 2 [41500/60000] (69%)\tLoss: 0.243576\n",
      "Train Epoch: 2 [42000/60000] (70%)\tLoss: 0.724667\n",
      "Train Epoch: 2 [42500/60000] (71%)\tLoss: 0.319910\n",
      "Train Epoch: 2 [43000/60000] (72%)\tLoss: 0.369889\n",
      "Train Epoch: 2 [43500/60000] (72%)\tLoss: 0.278715\n",
      "Train Epoch: 2 [44000/60000] (73%)\tLoss: 0.262132\n",
      "Train Epoch: 2 [44500/60000] (74%)\tLoss: 0.345897\n",
      "Train Epoch: 2 [45000/60000] (75%)\tLoss: 0.403256\n",
      "Train Epoch: 2 [45500/60000] (76%)\tLoss: 0.223844\n",
      "Train Epoch: 2 [46000/60000] (77%)\tLoss: 0.481971\n",
      "Train Epoch: 2 [46500/60000] (78%)\tLoss: 0.335488\n",
      "Train Epoch: 2 [47000/60000] (78%)\tLoss: 0.367864\n",
      "Train Epoch: 2 [47500/60000] (79%)\tLoss: 0.385457\n",
      "Train Epoch: 2 [48000/60000] (80%)\tLoss: 0.265691\n",
      "Train Epoch: 2 [48500/60000] (81%)\tLoss: 0.515452\n",
      "Train Epoch: 2 [49000/60000] (82%)\tLoss: 0.223004\n",
      "Train Epoch: 2 [49500/60000] (82%)\tLoss: 0.257186\n",
      "Train Epoch: 2 [50000/60000] (83%)\tLoss: 0.128270\n",
      "Train Epoch: 2 [50500/60000] (84%)\tLoss: 0.377703\n",
      "Train Epoch: 2 [51000/60000] (85%)\tLoss: 0.365308\n",
      "Train Epoch: 2 [51500/60000] (86%)\tLoss: 0.620444\n",
      "Train Epoch: 2 [52000/60000] (87%)\tLoss: 0.346886\n",
      "Train Epoch: 2 [52500/60000] (88%)\tLoss: 0.283585\n",
      "Train Epoch: 2 [53000/60000] (88%)\tLoss: 0.368580\n",
      "Train Epoch: 2 [53500/60000] (89%)\tLoss: 0.140838\n",
      "Train Epoch: 2 [54000/60000] (90%)\tLoss: 0.239561\n",
      "Train Epoch: 2 [54500/60000] (91%)\tLoss: 0.270098\n",
      "Train Epoch: 2 [55000/60000] (92%)\tLoss: 0.234446\n",
      "Train Epoch: 2 [55500/60000] (92%)\tLoss: 0.495854\n",
      "Train Epoch: 2 [56000/60000] (93%)\tLoss: 0.193098\n",
      "Train Epoch: 2 [56500/60000] (94%)\tLoss: 0.157676\n",
      "Train Epoch: 2 [57000/60000] (95%)\tLoss: 0.348409\n",
      "Train Epoch: 2 [57500/60000] (96%)\tLoss: 0.385411\n",
      "Train Epoch: 2 [58000/60000] (97%)\tLoss: 0.301383\n",
      "Train Epoch: 2 [58500/60000] (98%)\tLoss: 0.227730\n",
      "Train Epoch: 2 [59000/60000] (98%)\tLoss: 0.227687\n",
      "Train Epoch: 2 [59500/60000] (99%)\tLoss: 0.221552\n",
      "\n",
      "Test Set: Avg. Loss: 0.1307, Accuracy: 9591/10000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/60000] (0%)\tLoss: 0.263678\n",
      "Train Epoch: 3 [500/60000] (1%)\tLoss: 0.238961\n",
      "Train Epoch: 3 [1000/60000] (2%)\tLoss: 0.338218\n",
      "Train Epoch: 3 [1500/60000] (2%)\tLoss: 0.416943\n",
      "Train Epoch: 3 [2000/60000] (3%)\tLoss: 0.531940\n",
      "Train Epoch: 3 [2500/60000] (4%)\tLoss: 0.257828\n",
      "Train Epoch: 3 [3000/60000] (5%)\tLoss: 0.259518\n",
      "Train Epoch: 3 [3500/60000] (6%)\tLoss: 0.437653\n",
      "Train Epoch: 3 [4000/60000] (7%)\tLoss: 0.150669\n",
      "Train Epoch: 3 [4500/60000] (8%)\tLoss: 0.423531\n",
      "Train Epoch: 3 [5000/60000] (8%)\tLoss: 0.285581\n",
      "Train Epoch: 3 [5500/60000] (9%)\tLoss: 0.149881\n",
      "Train Epoch: 3 [6000/60000] (10%)\tLoss: 0.315636\n",
      "Train Epoch: 3 [6500/60000] (11%)\tLoss: 0.680015\n",
      "Train Epoch: 3 [7000/60000] (12%)\tLoss: 0.187701\n",
      "Train Epoch: 3 [7500/60000] (12%)\tLoss: 0.191079\n",
      "Train Epoch: 3 [8000/60000] (13%)\tLoss: 0.319586\n",
      "Train Epoch: 3 [8500/60000] (14%)\tLoss: 0.267757\n",
      "Train Epoch: 3 [9000/60000] (15%)\tLoss: 0.238213\n",
      "Train Epoch: 3 [9500/60000] (16%)\tLoss: 0.395917\n",
      "Train Epoch: 3 [10000/60000] (17%)\tLoss: 0.397697\n",
      "Train Epoch: 3 [10500/60000] (18%)\tLoss: 0.492663\n",
      "Train Epoch: 3 [11000/60000] (18%)\tLoss: 0.292097\n",
      "Train Epoch: 3 [11500/60000] (19%)\tLoss: 0.317092\n",
      "Train Epoch: 3 [12000/60000] (20%)\tLoss: 0.254780\n",
      "Train Epoch: 3 [12500/60000] (21%)\tLoss: 0.295469\n",
      "Train Epoch: 3 [13000/60000] (22%)\tLoss: 0.400168\n",
      "Train Epoch: 3 [13500/60000] (22%)\tLoss: 0.230643\n",
      "Train Epoch: 3 [14000/60000] (23%)\tLoss: 0.472653\n",
      "Train Epoch: 3 [14500/60000] (24%)\tLoss: 0.372290\n",
      "Train Epoch: 3 [15000/60000] (25%)\tLoss: 0.309630\n",
      "Train Epoch: 3 [15500/60000] (26%)\tLoss: 0.431957\n",
      "Train Epoch: 3 [16000/60000] (27%)\tLoss: 0.307138\n",
      "Train Epoch: 3 [16500/60000] (28%)\tLoss: 0.381260\n",
      "Train Epoch: 3 [17000/60000] (28%)\tLoss: 0.346683\n",
      "Train Epoch: 3 [17500/60000] (29%)\tLoss: 0.274492\n",
      "Train Epoch: 3 [18000/60000] (30%)\tLoss: 0.335737\n",
      "Train Epoch: 3 [18500/60000] (31%)\tLoss: 0.314954\n",
      "Train Epoch: 3 [19000/60000] (32%)\tLoss: 0.405985\n",
      "Train Epoch: 3 [19500/60000] (32%)\tLoss: 0.247520\n",
      "Train Epoch: 3 [20000/60000] (33%)\tLoss: 0.288680\n",
      "Train Epoch: 3 [20500/60000] (34%)\tLoss: 0.494357\n",
      "Train Epoch: 3 [21000/60000] (35%)\tLoss: 0.153741\n",
      "Train Epoch: 3 [21500/60000] (36%)\tLoss: 0.413673\n",
      "Train Epoch: 3 [22000/60000] (37%)\tLoss: 0.226476\n",
      "Train Epoch: 3 [22500/60000] (38%)\tLoss: 0.389660\n",
      "Train Epoch: 3 [23000/60000] (38%)\tLoss: 0.381931\n",
      "Train Epoch: 3 [23500/60000] (39%)\tLoss: 0.434349\n",
      "Train Epoch: 3 [24000/60000] (40%)\tLoss: 0.229079\n",
      "Train Epoch: 3 [24500/60000] (41%)\tLoss: 0.222155\n",
      "Train Epoch: 3 [25000/60000] (42%)\tLoss: 0.365286\n",
      "Train Epoch: 3 [25500/60000] (42%)\tLoss: 0.351262\n",
      "Train Epoch: 3 [26000/60000] (43%)\tLoss: 0.319876\n",
      "Train Epoch: 3 [26500/60000] (44%)\tLoss: 0.453665\n",
      "Train Epoch: 3 [27000/60000] (45%)\tLoss: 0.580547\n",
      "Train Epoch: 3 [27500/60000] (46%)\tLoss: 0.430620\n",
      "Train Epoch: 3 [28000/60000] (47%)\tLoss: 0.355104\n",
      "Train Epoch: 3 [28500/60000] (48%)\tLoss: 0.172767\n",
      "Train Epoch: 3 [29000/60000] (48%)\tLoss: 0.240972\n",
      "Train Epoch: 3 [29500/60000] (49%)\tLoss: 0.322114\n",
      "Train Epoch: 3 [30000/60000] (50%)\tLoss: 0.344242\n",
      "Train Epoch: 3 [30500/60000] (51%)\tLoss: 0.186445\n",
      "Train Epoch: 3 [31000/60000] (52%)\tLoss: 0.195255\n",
      "Train Epoch: 3 [31500/60000] (52%)\tLoss: 0.408307\n",
      "Train Epoch: 3 [32000/60000] (53%)\tLoss: 0.303461\n",
      "Train Epoch: 3 [32500/60000] (54%)\tLoss: 0.430735\n",
      "Train Epoch: 3 [33000/60000] (55%)\tLoss: 0.475572\n",
      "Train Epoch: 3 [33500/60000] (56%)\tLoss: 0.173828\n",
      "Train Epoch: 3 [34000/60000] (57%)\tLoss: 0.371526\n",
      "Train Epoch: 3 [34500/60000] (58%)\tLoss: 0.692307\n",
      "Train Epoch: 3 [35000/60000] (58%)\tLoss: 0.143296\n",
      "Train Epoch: 3 [35500/60000] (59%)\tLoss: 0.135292\n",
      "Train Epoch: 3 [36000/60000] (60%)\tLoss: 0.313536\n",
      "Train Epoch: 3 [36500/60000] (61%)\tLoss: 0.146325\n",
      "Train Epoch: 3 [37000/60000] (62%)\tLoss: 0.363834\n",
      "Train Epoch: 3 [37500/60000] (62%)\tLoss: 0.494128\n",
      "Train Epoch: 3 [38000/60000] (63%)\tLoss: 0.350276\n",
      "Train Epoch: 3 [38500/60000] (64%)\tLoss: 0.391818\n",
      "Train Epoch: 3 [39000/60000] (65%)\tLoss: 0.353542\n",
      "Train Epoch: 3 [39500/60000] (66%)\tLoss: 0.399281\n",
      "Train Epoch: 3 [40000/60000] (67%)\tLoss: 0.249593\n",
      "Train Epoch: 3 [40500/60000] (68%)\tLoss: 0.313907\n",
      "Train Epoch: 3 [41000/60000] (68%)\tLoss: 0.285739\n",
      "Train Epoch: 3 [41500/60000] (69%)\tLoss: 0.413522\n",
      "Train Epoch: 3 [42000/60000] (70%)\tLoss: 0.367758\n",
      "Train Epoch: 3 [42500/60000] (71%)\tLoss: 0.705935\n",
      "Train Epoch: 3 [43000/60000] (72%)\tLoss: 0.285378\n",
      "Train Epoch: 3 [43500/60000] (72%)\tLoss: 0.463984\n",
      "Train Epoch: 3 [44000/60000] (73%)\tLoss: 0.452374\n",
      "Train Epoch: 3 [44500/60000] (74%)\tLoss: 0.253027\n",
      "Train Epoch: 3 [45000/60000] (75%)\tLoss: 0.251241\n",
      "Train Epoch: 3 [45500/60000] (76%)\tLoss: 0.408704\n",
      "Train Epoch: 3 [46000/60000] (77%)\tLoss: 0.301555\n",
      "Train Epoch: 3 [46500/60000] (78%)\tLoss: 0.523074\n",
      "Train Epoch: 3 [47000/60000] (78%)\tLoss: 0.219489\n",
      "Train Epoch: 3 [47500/60000] (79%)\tLoss: 0.388799\n",
      "Train Epoch: 3 [48000/60000] (80%)\tLoss: 0.330736\n",
      "Train Epoch: 3 [48500/60000] (81%)\tLoss: 0.109881\n",
      "Train Epoch: 3 [49000/60000] (82%)\tLoss: 0.382778\n",
      "Train Epoch: 3 [49500/60000] (82%)\tLoss: 0.355792\n",
      "Train Epoch: 3 [50000/60000] (83%)\tLoss: 0.217565\n",
      "Train Epoch: 3 [50500/60000] (84%)\tLoss: 0.207969\n",
      "Train Epoch: 3 [51000/60000] (85%)\tLoss: 0.347407\n",
      "Train Epoch: 3 [51500/60000] (86%)\tLoss: 0.224558\n",
      "Train Epoch: 3 [52000/60000] (87%)\tLoss: 0.198682\n",
      "Train Epoch: 3 [52500/60000] (88%)\tLoss: 0.311436\n",
      "Train Epoch: 3 [53000/60000] (88%)\tLoss: 0.234307\n",
      "Train Epoch: 3 [53500/60000] (89%)\tLoss: 0.161766\n",
      "Train Epoch: 3 [54000/60000] (90%)\tLoss: 0.346087\n",
      "Train Epoch: 3 [54500/60000] (91%)\tLoss: 0.296377\n",
      "Train Epoch: 3 [55000/60000] (92%)\tLoss: 0.146315\n",
      "Train Epoch: 3 [55500/60000] (92%)\tLoss: 0.246294\n",
      "Train Epoch: 3 [56000/60000] (93%)\tLoss: 0.436886\n",
      "Train Epoch: 3 [56500/60000] (94%)\tLoss: 0.363066\n",
      "Train Epoch: 3 [57000/60000] (95%)\tLoss: 0.352690\n",
      "Train Epoch: 3 [57500/60000] (96%)\tLoss: 0.275346\n",
      "Train Epoch: 3 [58000/60000] (97%)\tLoss: 0.467316\n",
      "Train Epoch: 3 [58500/60000] (98%)\tLoss: 0.461854\n",
      "Train Epoch: 3 [59000/60000] (98%)\tLoss: 0.311672\n",
      "Train Epoch: 3 [59500/60000] (99%)\tLoss: 0.314453\n",
      "\n",
      "Test Set: Avg. Loss: 0.1275, Accuracy: 9598/10000 (96%)\n",
      "\n",
      "Train Epoch: 4 [0/60000] (0%)\tLoss: 0.323063\n",
      "Train Epoch: 4 [500/60000] (1%)\tLoss: 0.281778\n",
      "Train Epoch: 4 [1000/60000] (2%)\tLoss: 0.325710\n",
      "Train Epoch: 4 [1500/60000] (2%)\tLoss: 0.308010\n",
      "Train Epoch: 4 [2000/60000] (3%)\tLoss: 0.180452\n",
      "Train Epoch: 4 [2500/60000] (4%)\tLoss: 0.223397\n",
      "Train Epoch: 4 [3000/60000] (5%)\tLoss: 0.273343\n",
      "Train Epoch: 4 [3500/60000] (6%)\tLoss: 0.428412\n",
      "Train Epoch: 4 [4000/60000] (7%)\tLoss: 0.243039\n",
      "Train Epoch: 4 [4500/60000] (8%)\tLoss: 0.204347\n",
      "Train Epoch: 4 [5000/60000] (8%)\tLoss: 0.372813\n",
      "Train Epoch: 4 [5500/60000] (9%)\tLoss: 0.313768\n",
      "Train Epoch: 4 [6000/60000] (10%)\tLoss: 0.514099\n",
      "Train Epoch: 4 [6500/60000] (11%)\tLoss: 0.333335\n",
      "Train Epoch: 4 [7000/60000] (12%)\tLoss: 0.385496\n",
      "Train Epoch: 4 [7500/60000] (12%)\tLoss: 0.359116\n",
      "Train Epoch: 4 [8000/60000] (13%)\tLoss: 0.516281\n",
      "Train Epoch: 4 [8500/60000] (14%)\tLoss: 0.381862\n",
      "Train Epoch: 4 [9000/60000] (15%)\tLoss: 0.572261\n",
      "Train Epoch: 4 [9500/60000] (16%)\tLoss: 0.267296\n",
      "Train Epoch: 4 [10000/60000] (17%)\tLoss: 0.417125\n",
      "Train Epoch: 4 [10500/60000] (18%)\tLoss: 0.143298\n",
      "Train Epoch: 4 [11000/60000] (18%)\tLoss: 0.286047\n",
      "Train Epoch: 4 [11500/60000] (19%)\tLoss: 0.196181\n",
      "Train Epoch: 4 [12000/60000] (20%)\tLoss: 0.175489\n",
      "Train Epoch: 4 [12500/60000] (21%)\tLoss: 0.215267\n",
      "Train Epoch: 4 [13000/60000] (22%)\tLoss: 0.251294\n",
      "Train Epoch: 4 [13500/60000] (22%)\tLoss: 0.298716\n",
      "Train Epoch: 4 [14000/60000] (23%)\tLoss: 0.166398\n",
      "Train Epoch: 4 [14500/60000] (24%)\tLoss: 0.366423\n",
      "Train Epoch: 4 [15000/60000] (25%)\tLoss: 0.263675\n",
      "Train Epoch: 4 [15500/60000] (26%)\tLoss: 0.286505\n",
      "Train Epoch: 4 [16000/60000] (27%)\tLoss: 0.198670\n",
      "Train Epoch: 4 [16500/60000] (28%)\tLoss: 0.262561\n",
      "Train Epoch: 4 [17000/60000] (28%)\tLoss: 0.170843\n",
      "Train Epoch: 4 [17500/60000] (29%)\tLoss: 0.292981\n",
      "Train Epoch: 4 [18000/60000] (30%)\tLoss: 0.120552\n",
      "Train Epoch: 4 [18500/60000] (31%)\tLoss: 0.264687\n",
      "Train Epoch: 4 [19000/60000] (32%)\tLoss: 0.309968\n",
      "Train Epoch: 4 [19500/60000] (32%)\tLoss: 0.364853\n",
      "Train Epoch: 4 [20000/60000] (33%)\tLoss: 0.197178\n",
      "Train Epoch: 4 [20500/60000] (34%)\tLoss: 0.275598\n",
      "Train Epoch: 4 [21000/60000] (35%)\tLoss: 0.456912\n",
      "Train Epoch: 4 [21500/60000] (36%)\tLoss: 0.216766\n",
      "Train Epoch: 4 [22000/60000] (37%)\tLoss: 0.616387\n",
      "Train Epoch: 4 [22500/60000] (38%)\tLoss: 0.264696\n",
      "Train Epoch: 4 [23000/60000] (38%)\tLoss: 0.189522\n",
      "Train Epoch: 4 [23500/60000] (39%)\tLoss: 0.189556\n",
      "Train Epoch: 4 [24000/60000] (40%)\tLoss: 0.167340\n",
      "Train Epoch: 4 [24500/60000] (41%)\tLoss: 0.332711\n",
      "Train Epoch: 4 [25000/60000] (42%)\tLoss: 0.224516\n",
      "Train Epoch: 4 [25500/60000] (42%)\tLoss: 0.108750\n",
      "Train Epoch: 4 [26000/60000] (43%)\tLoss: 0.325213\n",
      "Train Epoch: 4 [26500/60000] (44%)\tLoss: 0.393064\n",
      "Train Epoch: 4 [27000/60000] (45%)\tLoss: 0.160973\n",
      "Train Epoch: 4 [27500/60000] (46%)\tLoss: 0.202001\n",
      "Train Epoch: 4 [28000/60000] (47%)\tLoss: 0.254449\n",
      "Train Epoch: 4 [28500/60000] (48%)\tLoss: 0.284149\n",
      "Train Epoch: 4 [29000/60000] (48%)\tLoss: 0.463608\n",
      "Train Epoch: 4 [29500/60000] (49%)\tLoss: 0.363195\n",
      "Train Epoch: 4 [30000/60000] (50%)\tLoss: 0.215983\n",
      "Train Epoch: 4 [30500/60000] (51%)\tLoss: 0.108533\n",
      "Train Epoch: 4 [31000/60000] (52%)\tLoss: 0.340469\n",
      "Train Epoch: 4 [31500/60000] (52%)\tLoss: 0.326063\n",
      "Train Epoch: 4 [32000/60000] (53%)\tLoss: 0.213882\n",
      "Train Epoch: 4 [32500/60000] (54%)\tLoss: 0.412366\n",
      "Train Epoch: 4 [33000/60000] (55%)\tLoss: 0.299279\n",
      "Train Epoch: 4 [33500/60000] (56%)\tLoss: 0.169198\n",
      "Train Epoch: 4 [34000/60000] (57%)\tLoss: 0.219268\n",
      "Train Epoch: 4 [34500/60000] (58%)\tLoss: 0.278923\n",
      "Train Epoch: 4 [35000/60000] (58%)\tLoss: 0.403003\n",
      "Train Epoch: 4 [35500/60000] (59%)\tLoss: 0.197579\n",
      "Train Epoch: 4 [36000/60000] (60%)\tLoss: 0.333518\n",
      "Train Epoch: 4 [36500/60000] (61%)\tLoss: 0.373738\n",
      "Train Epoch: 4 [37000/60000] (62%)\tLoss: 0.196458\n",
      "Train Epoch: 4 [37500/60000] (62%)\tLoss: 0.290689\n",
      "Train Epoch: 4 [38000/60000] (63%)\tLoss: 0.102003\n",
      "Train Epoch: 4 [38500/60000] (64%)\tLoss: 0.387415\n",
      "Train Epoch: 4 [39000/60000] (65%)\tLoss: 0.401977\n",
      "Train Epoch: 4 [39500/60000] (66%)\tLoss: 0.254373\n",
      "Train Epoch: 4 [40000/60000] (67%)\tLoss: 0.245669\n",
      "Train Epoch: 4 [40500/60000] (68%)\tLoss: 0.158864\n",
      "Train Epoch: 4 [41000/60000] (68%)\tLoss: 0.400392\n",
      "Train Epoch: 4 [41500/60000] (69%)\tLoss: 0.498411\n",
      "Train Epoch: 4 [42000/60000] (70%)\tLoss: 0.402480\n",
      "Train Epoch: 4 [42500/60000] (71%)\tLoss: 0.274549\n",
      "Train Epoch: 4 [43000/60000] (72%)\tLoss: 0.354179\n",
      "Train Epoch: 4 [43500/60000] (72%)\tLoss: 0.285746\n",
      "Train Epoch: 4 [44000/60000] (73%)\tLoss: 0.471474\n",
      "Train Epoch: 4 [44500/60000] (74%)\tLoss: 0.225587\n",
      "Train Epoch: 4 [45000/60000] (75%)\tLoss: 0.291506\n",
      "Train Epoch: 4 [45500/60000] (76%)\tLoss: 0.286292\n",
      "Train Epoch: 4 [46000/60000] (77%)\tLoss: 0.322218\n",
      "Train Epoch: 4 [46500/60000] (78%)\tLoss: 0.257209\n",
      "Train Epoch: 4 [47000/60000] (78%)\tLoss: 0.313605\n",
      "Train Epoch: 4 [47500/60000] (79%)\tLoss: 0.413634\n",
      "Train Epoch: 4 [48000/60000] (80%)\tLoss: 0.113807\n",
      "Train Epoch: 4 [48500/60000] (81%)\tLoss: 0.525791\n",
      "Train Epoch: 4 [49000/60000] (82%)\tLoss: 0.616099\n",
      "Train Epoch: 4 [49500/60000] (82%)\tLoss: 0.266948\n",
      "Train Epoch: 4 [50000/60000] (83%)\tLoss: 0.274671\n",
      "Train Epoch: 4 [50500/60000] (84%)\tLoss: 0.241132\n",
      "Train Epoch: 4 [51000/60000] (85%)\tLoss: 0.376510\n",
      "Train Epoch: 4 [51500/60000] (86%)\tLoss: 0.195940\n",
      "Train Epoch: 4 [52000/60000] (87%)\tLoss: 0.312462\n",
      "Train Epoch: 4 [52500/60000] (88%)\tLoss: 0.146720\n",
      "Train Epoch: 4 [53000/60000] (88%)\tLoss: 0.282058\n",
      "Train Epoch: 4 [53500/60000] (89%)\tLoss: 0.400535\n",
      "Train Epoch: 4 [54000/60000] (90%)\tLoss: 0.260245\n",
      "Train Epoch: 4 [54500/60000] (91%)\tLoss: 0.521382\n",
      "Train Epoch: 4 [55000/60000] (92%)\tLoss: 0.221086\n",
      "Train Epoch: 4 [55500/60000] (92%)\tLoss: 0.233161\n",
      "Train Epoch: 4 [56000/60000] (93%)\tLoss: 0.135328\n",
      "Train Epoch: 4 [56500/60000] (94%)\tLoss: 0.105617\n",
      "Train Epoch: 4 [57000/60000] (95%)\tLoss: 0.482999\n",
      "Train Epoch: 4 [57500/60000] (96%)\tLoss: 0.207082\n",
      "Train Epoch: 4 [58000/60000] (97%)\tLoss: 0.138104\n",
      "Train Epoch: 4 [58500/60000] (98%)\tLoss: 0.123696\n",
      "Train Epoch: 4 [59000/60000] (98%)\tLoss: 0.362099\n",
      "Train Epoch: 4 [59500/60000] (99%)\tLoss: 0.230642\n",
      "\n",
      "Test Set: Avg. Loss: 0.1239, Accuracy: 9612/10000 (96%)\n",
      "\n",
      "Train Epoch: 5 [0/60000] (0%)\tLoss: 0.136522\n",
      "Train Epoch: 5 [500/60000] (1%)\tLoss: 0.210177\n",
      "Train Epoch: 5 [1000/60000] (2%)\tLoss: 0.225109\n",
      "Train Epoch: 5 [1500/60000] (2%)\tLoss: 0.284524\n",
      "Train Epoch: 5 [2000/60000] (3%)\tLoss: 0.087750\n",
      "Train Epoch: 5 [2500/60000] (4%)\tLoss: 0.340452\n",
      "Train Epoch: 5 [3000/60000] (5%)\tLoss: 0.156702\n",
      "Train Epoch: 5 [3500/60000] (6%)\tLoss: 0.188459\n",
      "Train Epoch: 5 [4000/60000] (7%)\tLoss: 0.216081\n",
      "Train Epoch: 5 [4500/60000] (8%)\tLoss: 0.326758\n",
      "Train Epoch: 5 [5000/60000] (8%)\tLoss: 0.496952\n",
      "Train Epoch: 5 [5500/60000] (9%)\tLoss: 0.305918\n",
      "Train Epoch: 5 [6000/60000] (10%)\tLoss: 0.136269\n",
      "Train Epoch: 5 [6500/60000] (11%)\tLoss: 0.200145\n",
      "Train Epoch: 5 [7000/60000] (12%)\tLoss: 0.471835\n",
      "Train Epoch: 5 [7500/60000] (12%)\tLoss: 0.293421\n",
      "Train Epoch: 5 [8000/60000] (13%)\tLoss: 0.288804\n",
      "Train Epoch: 5 [8500/60000] (14%)\tLoss: 0.550326\n",
      "Train Epoch: 5 [9000/60000] (15%)\tLoss: 0.334073\n",
      "Train Epoch: 5 [9500/60000] (16%)\tLoss: 0.272391\n",
      "Train Epoch: 5 [10000/60000] (17%)\tLoss: 0.183539\n",
      "Train Epoch: 5 [10500/60000] (18%)\tLoss: 0.446030\n",
      "Train Epoch: 5 [11000/60000] (18%)\tLoss: 0.120283\n",
      "Train Epoch: 5 [11500/60000] (19%)\tLoss: 0.262614\n",
      "Train Epoch: 5 [12000/60000] (20%)\tLoss: 0.832437\n",
      "Train Epoch: 5 [12500/60000] (21%)\tLoss: 0.151423\n",
      "Train Epoch: 5 [13000/60000] (22%)\tLoss: 0.347656\n",
      "Train Epoch: 5 [13500/60000] (22%)\tLoss: 0.332018\n",
      "Train Epoch: 5 [14000/60000] (23%)\tLoss: 0.361701\n",
      "Train Epoch: 5 [14500/60000] (24%)\tLoss: 0.321455\n",
      "Train Epoch: 5 [15000/60000] (25%)\tLoss: 0.438569\n",
      "Train Epoch: 5 [15500/60000] (26%)\tLoss: 0.457278\n",
      "Train Epoch: 5 [16000/60000] (27%)\tLoss: 0.421466\n",
      "Train Epoch: 5 [16500/60000] (28%)\tLoss: 0.301654\n",
      "Train Epoch: 5 [17000/60000] (28%)\tLoss: 0.346801\n",
      "Train Epoch: 5 [17500/60000] (29%)\tLoss: 0.609352\n",
      "Train Epoch: 5 [18000/60000] (30%)\tLoss: 0.298628\n",
      "Train Epoch: 5 [18500/60000] (31%)\tLoss: 0.340899\n",
      "Train Epoch: 5 [19000/60000] (32%)\tLoss: 0.317436\n",
      "Train Epoch: 5 [19500/60000] (32%)\tLoss: 0.456249\n",
      "Train Epoch: 5 [20000/60000] (33%)\tLoss: 0.668707\n",
      "Train Epoch: 5 [20500/60000] (34%)\tLoss: 0.153786\n",
      "Train Epoch: 5 [21000/60000] (35%)\tLoss: 0.220815\n",
      "Train Epoch: 5 [21500/60000] (36%)\tLoss: 0.343851\n",
      "Train Epoch: 5 [22000/60000] (37%)\tLoss: 0.481472\n",
      "Train Epoch: 5 [22500/60000] (38%)\tLoss: 0.436280\n",
      "Train Epoch: 5 [23000/60000] (38%)\tLoss: 0.132583\n",
      "Train Epoch: 5 [23500/60000] (39%)\tLoss: 0.263618\n",
      "Train Epoch: 5 [24000/60000] (40%)\tLoss: 0.260937\n",
      "Train Epoch: 5 [24500/60000] (41%)\tLoss: 0.311266\n",
      "Train Epoch: 5 [25000/60000] (42%)\tLoss: 0.199122\n",
      "Train Epoch: 5 [25500/60000] (42%)\tLoss: 0.344744\n",
      "Train Epoch: 5 [26000/60000] (43%)\tLoss: 0.349488\n",
      "Train Epoch: 5 [26500/60000] (44%)\tLoss: 0.287073\n",
      "Train Epoch: 5 [27000/60000] (45%)\tLoss: 0.255904\n",
      "Train Epoch: 5 [27500/60000] (46%)\tLoss: 0.622302\n",
      "Train Epoch: 5 [28000/60000] (47%)\tLoss: 0.221134\n",
      "Train Epoch: 5 [28500/60000] (48%)\tLoss: 0.325093\n",
      "Train Epoch: 5 [29000/60000] (48%)\tLoss: 0.325047\n",
      "Train Epoch: 5 [29500/60000] (49%)\tLoss: 0.294146\n",
      "Train Epoch: 5 [30000/60000] (50%)\tLoss: 0.308276\n",
      "Train Epoch: 5 [30500/60000] (51%)\tLoss: 0.523522\n",
      "Train Epoch: 5 [31000/60000] (52%)\tLoss: 0.212694\n",
      "Train Epoch: 5 [31500/60000] (52%)\tLoss: 0.273168\n",
      "Train Epoch: 5 [32000/60000] (53%)\tLoss: 0.233192\n",
      "Train Epoch: 5 [32500/60000] (54%)\tLoss: 0.441838\n",
      "Train Epoch: 5 [33000/60000] (55%)\tLoss: 0.387232\n",
      "Train Epoch: 5 [33500/60000] (56%)\tLoss: 0.452834\n",
      "Train Epoch: 5 [34000/60000] (57%)\tLoss: 0.259331\n",
      "Train Epoch: 5 [34500/60000] (58%)\tLoss: 0.404683\n",
      "Train Epoch: 5 [35000/60000] (58%)\tLoss: 0.180389\n",
      "Train Epoch: 5 [35500/60000] (59%)\tLoss: 0.343935\n",
      "Train Epoch: 5 [36000/60000] (60%)\tLoss: 0.226947\n",
      "Train Epoch: 5 [36500/60000] (61%)\tLoss: 0.182275\n",
      "Train Epoch: 5 [37000/60000] (62%)\tLoss: 0.280592\n",
      "Train Epoch: 5 [37500/60000] (62%)\tLoss: 0.270240\n",
      "Train Epoch: 5 [38000/60000] (63%)\tLoss: 0.435671\n",
      "Train Epoch: 5 [38500/60000] (64%)\tLoss: 0.340115\n",
      "Train Epoch: 5 [39000/60000] (65%)\tLoss: 0.101841\n",
      "Train Epoch: 5 [39500/60000] (66%)\tLoss: 0.539853\n",
      "Train Epoch: 5 [40000/60000] (67%)\tLoss: 0.420443\n",
      "Train Epoch: 5 [40500/60000] (68%)\tLoss: 0.552789\n",
      "Train Epoch: 5 [41000/60000] (68%)\tLoss: 0.211914\n",
      "Train Epoch: 5 [41500/60000] (69%)\tLoss: 0.351210\n",
      "Train Epoch: 5 [42000/60000] (70%)\tLoss: 0.263049\n",
      "Train Epoch: 5 [42500/60000] (71%)\tLoss: 0.291030\n",
      "Train Epoch: 5 [43000/60000] (72%)\tLoss: 0.523489\n",
      "Train Epoch: 5 [43500/60000] (72%)\tLoss: 0.205070\n",
      "Train Epoch: 5 [44000/60000] (73%)\tLoss: 0.375036\n",
      "Train Epoch: 5 [44500/60000] (74%)\tLoss: 0.174274\n",
      "Train Epoch: 5 [45000/60000] (75%)\tLoss: 0.294022\n",
      "Train Epoch: 5 [45500/60000] (76%)\tLoss: 0.735648\n",
      "Train Epoch: 5 [46000/60000] (77%)\tLoss: 0.217768\n",
      "Train Epoch: 5 [46500/60000] (78%)\tLoss: 0.246246\n",
      "Train Epoch: 5 [47000/60000] (78%)\tLoss: 0.367428\n",
      "Train Epoch: 5 [47500/60000] (79%)\tLoss: 0.369045\n",
      "Train Epoch: 5 [48000/60000] (80%)\tLoss: 0.354333\n",
      "Train Epoch: 5 [48500/60000] (81%)\tLoss: 0.302269\n",
      "Train Epoch: 5 [49000/60000] (82%)\tLoss: 0.370020\n",
      "Train Epoch: 5 [49500/60000] (82%)\tLoss: 0.324892\n",
      "Train Epoch: 5 [50000/60000] (83%)\tLoss: 0.299980\n",
      "Train Epoch: 5 [50500/60000] (84%)\tLoss: 0.260894\n",
      "Train Epoch: 5 [51000/60000] (85%)\tLoss: 0.182340\n",
      "Train Epoch: 5 [51500/60000] (86%)\tLoss: 0.219818\n",
      "Train Epoch: 5 [52000/60000] (87%)\tLoss: 0.300956\n",
      "Train Epoch: 5 [52500/60000] (88%)\tLoss: 0.584912\n",
      "Train Epoch: 5 [53000/60000] (88%)\tLoss: 0.431543\n",
      "Train Epoch: 5 [53500/60000] (89%)\tLoss: 0.184149\n",
      "Train Epoch: 5 [54000/60000] (90%)\tLoss: 0.488448\n",
      "Train Epoch: 5 [54500/60000] (91%)\tLoss: 0.256871\n",
      "Train Epoch: 5 [55000/60000] (92%)\tLoss: 0.127472\n",
      "Train Epoch: 5 [55500/60000] (92%)\tLoss: 0.386562\n",
      "Train Epoch: 5 [56000/60000] (93%)\tLoss: 0.284313\n",
      "Train Epoch: 5 [56500/60000] (94%)\tLoss: 0.324741\n",
      "Train Epoch: 5 [57000/60000] (95%)\tLoss: 0.179582\n",
      "Train Epoch: 5 [57500/60000] (96%)\tLoss: 0.143977\n",
      "Train Epoch: 5 [58000/60000] (97%)\tLoss: 0.262955\n",
      "Train Epoch: 5 [58500/60000] (98%)\tLoss: 0.418057\n",
      "Train Epoch: 5 [59000/60000] (98%)\tLoss: 0.182068\n",
      "Train Epoch: 5 [59500/60000] (99%)\tLoss: 0.372820\n",
      "\n",
      "Test Set: Avg. Loss: 0.1210, Accuracy: 9627/10000 (96%)\n",
      "\n",
      "Train Epoch: 6 [0/60000] (0%)\tLoss: 0.327879\n",
      "Train Epoch: 6 [500/60000] (1%)\tLoss: 0.290118\n",
      "Train Epoch: 6 [1000/60000] (2%)\tLoss: 0.238328\n",
      "Train Epoch: 6 [1500/60000] (2%)\tLoss: 0.314400\n",
      "Train Epoch: 6 [2000/60000] (3%)\tLoss: 0.271878\n",
      "Train Epoch: 6 [2500/60000] (4%)\tLoss: 0.314006\n",
      "Train Epoch: 6 [3000/60000] (5%)\tLoss: 0.370887\n",
      "Train Epoch: 6 [3500/60000] (6%)\tLoss: 0.295802\n",
      "Train Epoch: 6 [4000/60000] (7%)\tLoss: 0.413881\n",
      "Train Epoch: 6 [4500/60000] (8%)\tLoss: 0.281935\n",
      "Train Epoch: 6 [5000/60000] (8%)\tLoss: 0.315753\n",
      "Train Epoch: 6 [5500/60000] (9%)\tLoss: 0.340531\n",
      "Train Epoch: 6 [6000/60000] (10%)\tLoss: 0.340446\n",
      "Train Epoch: 6 [6500/60000] (11%)\tLoss: 0.459453\n",
      "Train Epoch: 6 [7000/60000] (12%)\tLoss: 0.348367\n",
      "Train Epoch: 6 [7500/60000] (12%)\tLoss: 0.211026\n",
      "Train Epoch: 6 [8000/60000] (13%)\tLoss: 0.265371\n",
      "Train Epoch: 6 [8500/60000] (14%)\tLoss: 0.178357\n",
      "Train Epoch: 6 [9000/60000] (15%)\tLoss: 0.253138\n",
      "Train Epoch: 6 [9500/60000] (16%)\tLoss: 0.173630\n",
      "Train Epoch: 6 [10000/60000] (17%)\tLoss: 0.238450\n",
      "Train Epoch: 6 [10500/60000] (18%)\tLoss: 0.156729\n",
      "Train Epoch: 6 [11000/60000] (18%)\tLoss: 0.232589\n",
      "Train Epoch: 6 [11500/60000] (19%)\tLoss: 0.204307\n",
      "Train Epoch: 6 [12000/60000] (20%)\tLoss: 0.262923\n",
      "Train Epoch: 6 [12500/60000] (21%)\tLoss: 0.209172\n",
      "Train Epoch: 6 [13000/60000] (22%)\tLoss: 0.344828\n",
      "Train Epoch: 6 [13500/60000] (22%)\tLoss: 0.430161\n",
      "Train Epoch: 6 [14000/60000] (23%)\tLoss: 0.300513\n",
      "Train Epoch: 6 [14500/60000] (24%)\tLoss: 0.446373\n",
      "Train Epoch: 6 [15000/60000] (25%)\tLoss: 0.453698\n",
      "Train Epoch: 6 [15500/60000] (26%)\tLoss: 0.147959\n",
      "Train Epoch: 6 [16000/60000] (27%)\tLoss: 0.475743\n",
      "Train Epoch: 6 [16500/60000] (28%)\tLoss: 0.128449\n",
      "Train Epoch: 6 [17000/60000] (28%)\tLoss: 0.303882\n",
      "Train Epoch: 6 [17500/60000] (29%)\tLoss: 0.220835\n",
      "Train Epoch: 6 [18000/60000] (30%)\tLoss: 0.273935\n",
      "Train Epoch: 6 [18500/60000] (31%)\tLoss: 0.303186\n",
      "Train Epoch: 6 [19000/60000] (32%)\tLoss: 0.375960\n",
      "Train Epoch: 6 [19500/60000] (32%)\tLoss: 0.421080\n",
      "Train Epoch: 6 [20000/60000] (33%)\tLoss: 0.215529\n",
      "Train Epoch: 6 [20500/60000] (34%)\tLoss: 0.303312\n",
      "Train Epoch: 6 [21000/60000] (35%)\tLoss: 0.262179\n",
      "Train Epoch: 6 [21500/60000] (36%)\tLoss: 0.263557\n",
      "Train Epoch: 6 [22000/60000] (37%)\tLoss: 0.122022\n",
      "Train Epoch: 6 [22500/60000] (38%)\tLoss: 0.216665\n",
      "Train Epoch: 6 [23000/60000] (38%)\tLoss: 0.214286\n",
      "Train Epoch: 6 [23500/60000] (39%)\tLoss: 0.449453\n",
      "Train Epoch: 6 [24000/60000] (40%)\tLoss: 0.358385\n",
      "Train Epoch: 6 [24500/60000] (41%)\tLoss: 0.120115\n",
      "Train Epoch: 6 [25000/60000] (42%)\tLoss: 0.258279\n",
      "Train Epoch: 6 [25500/60000] (42%)\tLoss: 0.248756\n",
      "Train Epoch: 6 [26000/60000] (43%)\tLoss: 0.360802\n",
      "Train Epoch: 6 [26500/60000] (44%)\tLoss: 0.516345\n",
      "Train Epoch: 6 [27000/60000] (45%)\tLoss: 0.232423\n",
      "Train Epoch: 6 [27500/60000] (46%)\tLoss: 0.327985\n",
      "Train Epoch: 6 [28000/60000] (47%)\tLoss: 0.209668\n",
      "Train Epoch: 6 [28500/60000] (48%)\tLoss: 0.224061\n",
      "Train Epoch: 6 [29000/60000] (48%)\tLoss: 0.297388\n",
      "Train Epoch: 6 [29500/60000] (49%)\tLoss: 0.223844\n",
      "Train Epoch: 6 [30000/60000] (50%)\tLoss: 0.179636\n",
      "Train Epoch: 6 [30500/60000] (51%)\tLoss: 0.363677\n",
      "Train Epoch: 6 [31000/60000] (52%)\tLoss: 0.301086\n",
      "Train Epoch: 6 [31500/60000] (52%)\tLoss: 0.220024\n",
      "Train Epoch: 6 [32000/60000] (53%)\tLoss: 0.229378\n",
      "Train Epoch: 6 [32500/60000] (54%)\tLoss: 0.324051\n",
      "Train Epoch: 6 [33000/60000] (55%)\tLoss: 0.339373\n",
      "Train Epoch: 6 [33500/60000] (56%)\tLoss: 0.293334\n",
      "Train Epoch: 6 [34000/60000] (57%)\tLoss: 0.387224\n",
      "Train Epoch: 6 [34500/60000] (58%)\tLoss: 0.151141\n",
      "Train Epoch: 6 [35000/60000] (58%)\tLoss: 0.284946\n",
      "Train Epoch: 6 [35500/60000] (59%)\tLoss: 0.249143\n",
      "Train Epoch: 6 [36000/60000] (60%)\tLoss: 0.406767\n",
      "Train Epoch: 6 [36500/60000] (61%)\tLoss: 0.332724\n",
      "Train Epoch: 6 [37000/60000] (62%)\tLoss: 0.326793\n",
      "Train Epoch: 6 [37500/60000] (62%)\tLoss: 0.318453\n",
      "Train Epoch: 6 [38000/60000] (63%)\tLoss: 0.436349\n",
      "Train Epoch: 6 [38500/60000] (64%)\tLoss: 0.350443\n",
      "Train Epoch: 6 [39000/60000] (65%)\tLoss: 0.439724\n",
      "Train Epoch: 6 [39500/60000] (66%)\tLoss: 0.341833\n",
      "Train Epoch: 6 [40000/60000] (67%)\tLoss: 0.205546\n",
      "Train Epoch: 6 [40500/60000] (68%)\tLoss: 0.174229\n",
      "Train Epoch: 6 [41000/60000] (68%)\tLoss: 0.258913\n",
      "Train Epoch: 6 [41500/60000] (69%)\tLoss: 0.220633\n",
      "Train Epoch: 6 [42000/60000] (70%)\tLoss: 0.176945\n",
      "Train Epoch: 6 [42500/60000] (71%)\tLoss: 0.333569\n",
      "Train Epoch: 6 [43000/60000] (72%)\tLoss: 0.453057\n",
      "Train Epoch: 6 [43500/60000] (72%)\tLoss: 0.244567\n",
      "Train Epoch: 6 [44000/60000] (73%)\tLoss: 0.374777\n",
      "Train Epoch: 6 [44500/60000] (74%)\tLoss: 0.399473\n",
      "Train Epoch: 6 [45000/60000] (75%)\tLoss: 0.308982\n",
      "Train Epoch: 6 [45500/60000] (76%)\tLoss: 0.172163\n",
      "Train Epoch: 6 [46000/60000] (77%)\tLoss: 0.232721\n",
      "Train Epoch: 6 [46500/60000] (78%)\tLoss: 0.525154\n",
      "Train Epoch: 6 [47000/60000] (78%)\tLoss: 0.064751\n",
      "Train Epoch: 6 [47500/60000] (79%)\tLoss: 0.133250\n",
      "Train Epoch: 6 [48000/60000] (80%)\tLoss: 0.188151\n",
      "Train Epoch: 6 [48500/60000] (81%)\tLoss: 0.451786\n",
      "Train Epoch: 6 [49000/60000] (82%)\tLoss: 0.361569\n",
      "Train Epoch: 6 [49500/60000] (82%)\tLoss: 0.398742\n",
      "Train Epoch: 6 [50000/60000] (83%)\tLoss: 0.268993\n",
      "Train Epoch: 6 [50500/60000] (84%)\tLoss: 0.339897\n",
      "Train Epoch: 6 [51000/60000] (85%)\tLoss: 0.157407\n",
      "Train Epoch: 6 [51500/60000] (86%)\tLoss: 0.238906\n",
      "Train Epoch: 6 [52000/60000] (87%)\tLoss: 0.196343\n",
      "Train Epoch: 6 [52500/60000] (88%)\tLoss: 0.216769\n",
      "Train Epoch: 6 [53000/60000] (88%)\tLoss: 0.241746\n",
      "Train Epoch: 6 [53500/60000] (89%)\tLoss: 0.352116\n",
      "Train Epoch: 6 [54000/60000] (90%)\tLoss: 0.355165\n",
      "Train Epoch: 6 [54500/60000] (91%)\tLoss: 0.296249\n",
      "Train Epoch: 6 [55000/60000] (92%)\tLoss: 0.378728\n",
      "Train Epoch: 6 [55500/60000] (92%)\tLoss: 0.304616\n",
      "Train Epoch: 6 [56000/60000] (93%)\tLoss: 0.308090\n",
      "Train Epoch: 6 [56500/60000] (94%)\tLoss: 0.302748\n",
      "Train Epoch: 6 [57000/60000] (95%)\tLoss: 0.219699\n",
      "Train Epoch: 6 [57500/60000] (96%)\tLoss: 0.517795\n",
      "Train Epoch: 6 [58000/60000] (97%)\tLoss: 0.438346\n",
      "Train Epoch: 6 [58500/60000] (98%)\tLoss: 0.180336\n",
      "Train Epoch: 6 [59000/60000] (98%)\tLoss: 0.166789\n",
      "Train Epoch: 6 [59500/60000] (99%)\tLoss: 0.218461\n",
      "\n",
      "Test Set: Avg. Loss: 0.1161, Accuracy: 9645/10000 (96%)\n",
      "\n",
      "Train Epoch: 7 [0/60000] (0%)\tLoss: 0.261838\n",
      "Train Epoch: 7 [500/60000] (1%)\tLoss: 0.312786\n",
      "Train Epoch: 7 [1000/60000] (2%)\tLoss: 0.200344\n",
      "Train Epoch: 7 [1500/60000] (2%)\tLoss: 0.534699\n",
      "Train Epoch: 7 [2000/60000] (3%)\tLoss: 0.256074\n",
      "Train Epoch: 7 [2500/60000] (4%)\tLoss: 0.317963\n",
      "Train Epoch: 7 [3000/60000] (5%)\tLoss: 0.508544\n",
      "Train Epoch: 7 [3500/60000] (6%)\tLoss: 0.242223\n",
      "Train Epoch: 7 [4000/60000] (7%)\tLoss: 0.184781\n",
      "Train Epoch: 7 [4500/60000] (8%)\tLoss: 0.335795\n",
      "Train Epoch: 7 [5000/60000] (8%)\tLoss: 0.355034\n",
      "Train Epoch: 7 [5500/60000] (9%)\tLoss: 0.346536\n",
      "Train Epoch: 7 [6000/60000] (10%)\tLoss: 0.422161\n",
      "Train Epoch: 7 [6500/60000] (11%)\tLoss: 0.270776\n",
      "Train Epoch: 7 [7000/60000] (12%)\tLoss: 0.138983\n",
      "Train Epoch: 7 [7500/60000] (12%)\tLoss: 0.304170\n",
      "Train Epoch: 7 [8000/60000] (13%)\tLoss: 0.386235\n",
      "Train Epoch: 7 [8500/60000] (14%)\tLoss: 0.226543\n",
      "Train Epoch: 7 [9000/60000] (15%)\tLoss: 0.180769\n",
      "Train Epoch: 7 [9500/60000] (16%)\tLoss: 0.109936\n",
      "Train Epoch: 7 [10000/60000] (17%)\tLoss: 0.194105\n",
      "Train Epoch: 7 [10500/60000] (18%)\tLoss: 0.419211\n",
      "Train Epoch: 7 [11000/60000] (18%)\tLoss: 0.355365\n",
      "Train Epoch: 7 [11500/60000] (19%)\tLoss: 0.174502\n",
      "Train Epoch: 7 [12000/60000] (20%)\tLoss: 0.180567\n",
      "Train Epoch: 7 [12500/60000] (21%)\tLoss: 0.292722\n",
      "Train Epoch: 7 [13000/60000] (22%)\tLoss: 0.397935\n",
      "Train Epoch: 7 [13500/60000] (22%)\tLoss: 0.428323\n",
      "Train Epoch: 7 [14000/60000] (23%)\tLoss: 0.270268\n",
      "Train Epoch: 7 [14500/60000] (24%)\tLoss: 0.178875\n",
      "Train Epoch: 7 [15000/60000] (25%)\tLoss: 0.170436\n",
      "Train Epoch: 7 [15500/60000] (26%)\tLoss: 0.119570\n",
      "Train Epoch: 7 [16000/60000] (27%)\tLoss: 0.291640\n",
      "Train Epoch: 7 [16500/60000] (28%)\tLoss: 0.421681\n",
      "Train Epoch: 7 [17000/60000] (28%)\tLoss: 0.259606\n",
      "Train Epoch: 7 [17500/60000] (29%)\tLoss: 0.375332\n",
      "Train Epoch: 7 [18000/60000] (30%)\tLoss: 0.295462\n",
      "Train Epoch: 7 [18500/60000] (31%)\tLoss: 0.292937\n",
      "Train Epoch: 7 [19000/60000] (32%)\tLoss: 0.208299\n",
      "Train Epoch: 7 [19500/60000] (32%)\tLoss: 0.263257\n",
      "Train Epoch: 7 [20000/60000] (33%)\tLoss: 0.208115\n",
      "Train Epoch: 7 [20500/60000] (34%)\tLoss: 0.569357\n",
      "Train Epoch: 7 [21000/60000] (35%)\tLoss: 0.161843\n",
      "Train Epoch: 7 [21500/60000] (36%)\tLoss: 0.334390\n",
      "Train Epoch: 7 [22000/60000] (37%)\tLoss: 0.461045\n",
      "Train Epoch: 7 [22500/60000] (38%)\tLoss: 0.438276\n",
      "Train Epoch: 7 [23000/60000] (38%)\tLoss: 0.355558\n",
      "Train Epoch: 7 [23500/60000] (39%)\tLoss: 0.150885\n",
      "Train Epoch: 7 [24000/60000] (40%)\tLoss: 0.308481\n",
      "Train Epoch: 7 [24500/60000] (41%)\tLoss: 0.251955\n",
      "Train Epoch: 7 [25000/60000] (42%)\tLoss: 0.234088\n",
      "Train Epoch: 7 [25500/60000] (42%)\tLoss: 0.312085\n",
      "Train Epoch: 7 [26000/60000] (43%)\tLoss: 0.323523\n",
      "Train Epoch: 7 [26500/60000] (44%)\tLoss: 0.103579\n",
      "Train Epoch: 7 [27000/60000] (45%)\tLoss: 0.432316\n",
      "Train Epoch: 7 [27500/60000] (46%)\tLoss: 0.324503\n",
      "Train Epoch: 7 [28000/60000] (47%)\tLoss: 0.468563\n",
      "Train Epoch: 7 [28500/60000] (48%)\tLoss: 0.255546\n",
      "Train Epoch: 7 [29000/60000] (48%)\tLoss: 0.357064\n",
      "Train Epoch: 7 [29500/60000] (49%)\tLoss: 0.390008\n",
      "Train Epoch: 7 [30000/60000] (50%)\tLoss: 0.317672\n",
      "Train Epoch: 7 [30500/60000] (51%)\tLoss: 0.165476\n",
      "Train Epoch: 7 [31000/60000] (52%)\tLoss: 0.263976\n",
      "Train Epoch: 7 [31500/60000] (52%)\tLoss: 0.199609\n",
      "Train Epoch: 7 [32000/60000] (53%)\tLoss: 0.437837\n",
      "Train Epoch: 7 [32500/60000] (54%)\tLoss: 0.251464\n",
      "Train Epoch: 7 [33000/60000] (55%)\tLoss: 0.299109\n",
      "Train Epoch: 7 [33500/60000] (56%)\tLoss: 0.356211\n",
      "Train Epoch: 7 [34000/60000] (57%)\tLoss: 0.271910\n",
      "Train Epoch: 7 [34500/60000] (58%)\tLoss: 0.244358\n",
      "Train Epoch: 7 [35000/60000] (58%)\tLoss: 0.346613\n",
      "Train Epoch: 7 [35500/60000] (59%)\tLoss: 0.370757\n",
      "Train Epoch: 7 [36000/60000] (60%)\tLoss: 0.331097\n",
      "Train Epoch: 7 [36500/60000] (61%)\tLoss: 0.357507\n",
      "Train Epoch: 7 [37000/60000] (62%)\tLoss: 0.272371\n",
      "Train Epoch: 7 [37500/60000] (62%)\tLoss: 0.292431\n",
      "Train Epoch: 7 [38000/60000] (63%)\tLoss: 0.178471\n",
      "Train Epoch: 7 [38500/60000] (64%)\tLoss: 0.272772\n",
      "Train Epoch: 7 [39000/60000] (65%)\tLoss: 0.313192\n",
      "Train Epoch: 7 [39500/60000] (66%)\tLoss: 0.225921\n",
      "Train Epoch: 7 [40000/60000] (67%)\tLoss: 0.182867\n",
      "Train Epoch: 7 [40500/60000] (68%)\tLoss: 0.551455\n",
      "Train Epoch: 7 [41000/60000] (68%)\tLoss: 0.259704\n",
      "Train Epoch: 7 [41500/60000] (69%)\tLoss: 0.304098\n",
      "Train Epoch: 7 [42000/60000] (70%)\tLoss: 0.235072\n",
      "Train Epoch: 7 [42500/60000] (71%)\tLoss: 0.342876\n",
      "Train Epoch: 7 [43000/60000] (72%)\tLoss: 0.733446\n",
      "Train Epoch: 7 [43500/60000] (72%)\tLoss: 0.142656\n",
      "Train Epoch: 7 [44000/60000] (73%)\tLoss: 0.229647\n",
      "Train Epoch: 7 [44500/60000] (74%)\tLoss: 0.282810\n",
      "Train Epoch: 7 [45000/60000] (75%)\tLoss: 0.197033\n",
      "Train Epoch: 7 [45500/60000] (76%)\tLoss: 0.348216\n",
      "Train Epoch: 7 [46000/60000] (77%)\tLoss: 0.292640\n",
      "Train Epoch: 7 [46500/60000] (78%)\tLoss: 0.219828\n",
      "Train Epoch: 7 [47000/60000] (78%)\tLoss: 0.445743\n",
      "Train Epoch: 7 [47500/60000] (79%)\tLoss: 0.463815\n",
      "Train Epoch: 7 [48000/60000] (80%)\tLoss: 0.357931\n",
      "Train Epoch: 7 [48500/60000] (81%)\tLoss: 0.173912\n",
      "Train Epoch: 7 [49000/60000] (82%)\tLoss: 0.259064\n",
      "Train Epoch: 7 [49500/60000] (82%)\tLoss: 0.578888\n",
      "Train Epoch: 7 [50000/60000] (83%)\tLoss: 0.238033\n",
      "Train Epoch: 7 [50500/60000] (84%)\tLoss: 0.201764\n",
      "Train Epoch: 7 [51000/60000] (85%)\tLoss: 0.466200\n",
      "Train Epoch: 7 [51500/60000] (86%)\tLoss: 0.410742\n",
      "Train Epoch: 7 [52000/60000] (87%)\tLoss: 0.265667\n",
      "Train Epoch: 7 [52500/60000] (88%)\tLoss: 0.250655\n",
      "Train Epoch: 7 [53000/60000] (88%)\tLoss: 0.371772\n",
      "Train Epoch: 7 [53500/60000] (89%)\tLoss: 0.172839\n",
      "Train Epoch: 7 [54000/60000] (90%)\tLoss: 0.217424\n",
      "Train Epoch: 7 [54500/60000] (91%)\tLoss: 0.401375\n",
      "Train Epoch: 7 [55000/60000] (92%)\tLoss: 0.110518\n",
      "Train Epoch: 7 [55500/60000] (92%)\tLoss: 0.166473\n",
      "Train Epoch: 7 [56000/60000] (93%)\tLoss: 0.434836\n",
      "Train Epoch: 7 [56500/60000] (94%)\tLoss: 0.350410\n",
      "Train Epoch: 7 [57000/60000] (95%)\tLoss: 0.283855\n",
      "Train Epoch: 7 [57500/60000] (96%)\tLoss: 0.328433\n",
      "Train Epoch: 7 [58000/60000] (97%)\tLoss: 0.331491\n",
      "Train Epoch: 7 [58500/60000] (98%)\tLoss: 0.329105\n",
      "Train Epoch: 7 [59000/60000] (98%)\tLoss: 0.183586\n",
      "Train Epoch: 7 [59500/60000] (99%)\tLoss: 0.175154\n",
      "\n",
      "Test Set: Avg. Loss: 0.1137, Accuracy: 9645/10000 (96%)\n",
      "\n",
      "Train Epoch: 8 [0/60000] (0%)\tLoss: 0.326486\n",
      "Train Epoch: 8 [500/60000] (1%)\tLoss: 0.600803\n",
      "Train Epoch: 8 [1000/60000] (2%)\tLoss: 0.515974\n",
      "Train Epoch: 8 [1500/60000] (2%)\tLoss: 0.133205\n",
      "Train Epoch: 8 [2000/60000] (3%)\tLoss: 0.267826\n",
      "Train Epoch: 8 [2500/60000] (4%)\tLoss: 0.213094\n",
      "Train Epoch: 8 [3000/60000] (5%)\tLoss: 0.321268\n",
      "Train Epoch: 8 [3500/60000] (6%)\tLoss: 0.148215\n",
      "Train Epoch: 8 [4000/60000] (7%)\tLoss: 0.235074\n",
      "Train Epoch: 8 [4500/60000] (8%)\tLoss: 0.321561\n",
      "Train Epoch: 8 [5000/60000] (8%)\tLoss: 0.366117\n",
      "Train Epoch: 8 [5500/60000] (9%)\tLoss: 0.273437\n",
      "Train Epoch: 8 [6000/60000] (10%)\tLoss: 0.287942\n",
      "Train Epoch: 8 [6500/60000] (11%)\tLoss: 0.570123\n",
      "Train Epoch: 8 [7000/60000] (12%)\tLoss: 0.353730\n",
      "Train Epoch: 8 [7500/60000] (12%)\tLoss: 0.283542\n",
      "Train Epoch: 8 [8000/60000] (13%)\tLoss: 0.293119\n",
      "Train Epoch: 8 [8500/60000] (14%)\tLoss: 0.302641\n",
      "Train Epoch: 8 [9000/60000] (15%)\tLoss: 0.139697\n",
      "Train Epoch: 8 [9500/60000] (16%)\tLoss: 0.200333\n",
      "Train Epoch: 8 [10000/60000] (17%)\tLoss: 0.295971\n",
      "Train Epoch: 8 [10500/60000] (18%)\tLoss: 0.224552\n",
      "Train Epoch: 8 [11000/60000] (18%)\tLoss: 0.307260\n",
      "Train Epoch: 8 [11500/60000] (19%)\tLoss: 0.324103\n",
      "Train Epoch: 8 [12000/60000] (20%)\tLoss: 0.360465\n",
      "Train Epoch: 8 [12500/60000] (21%)\tLoss: 0.209412\n",
      "Train Epoch: 8 [13000/60000] (22%)\tLoss: 0.139125\n",
      "Train Epoch: 8 [13500/60000] (22%)\tLoss: 0.364092\n",
      "Train Epoch: 8 [14000/60000] (23%)\tLoss: 0.308136\n",
      "Train Epoch: 8 [14500/60000] (24%)\tLoss: 0.437049\n",
      "Train Epoch: 8 [15000/60000] (25%)\tLoss: 0.380632\n",
      "Train Epoch: 8 [15500/60000] (26%)\tLoss: 0.303137\n",
      "Train Epoch: 8 [16000/60000] (27%)\tLoss: 0.356490\n",
      "Train Epoch: 8 [16500/60000] (28%)\tLoss: 0.159875\n",
      "Train Epoch: 8 [17000/60000] (28%)\tLoss: 0.375021\n",
      "Train Epoch: 8 [17500/60000] (29%)\tLoss: 0.166019\n",
      "Train Epoch: 8 [18000/60000] (30%)\tLoss: 0.269464\n",
      "Train Epoch: 8 [18500/60000] (31%)\tLoss: 0.128064\n",
      "Train Epoch: 8 [19000/60000] (32%)\tLoss: 0.182418\n",
      "Train Epoch: 8 [19500/60000] (32%)\tLoss: 0.386311\n",
      "Train Epoch: 8 [20000/60000] (33%)\tLoss: 0.333348\n",
      "Train Epoch: 8 [20500/60000] (34%)\tLoss: 0.247570\n",
      "Train Epoch: 8 [21000/60000] (35%)\tLoss: 0.226432\n",
      "Train Epoch: 8 [21500/60000] (36%)\tLoss: 0.397856\n",
      "Train Epoch: 8 [22000/60000] (37%)\tLoss: 0.371151\n",
      "Train Epoch: 8 [22500/60000] (38%)\tLoss: 0.279452\n",
      "Train Epoch: 8 [23000/60000] (38%)\tLoss: 0.379656\n",
      "Train Epoch: 8 [23500/60000] (39%)\tLoss: 0.245821\n",
      "Train Epoch: 8 [24000/60000] (40%)\tLoss: 0.189514\n",
      "Train Epoch: 8 [24500/60000] (41%)\tLoss: 0.214830\n",
      "Train Epoch: 8 [25000/60000] (42%)\tLoss: 0.282020\n",
      "Train Epoch: 8 [25500/60000] (42%)\tLoss: 0.207791\n",
      "Train Epoch: 8 [26000/60000] (43%)\tLoss: 0.239871\n",
      "Train Epoch: 8 [26500/60000] (44%)\tLoss: 0.283932\n",
      "Train Epoch: 8 [27000/60000] (45%)\tLoss: 0.418667\n",
      "Train Epoch: 8 [27500/60000] (46%)\tLoss: 0.105431\n",
      "Train Epoch: 8 [28000/60000] (47%)\tLoss: 0.162407\n",
      "Train Epoch: 8 [28500/60000] (48%)\tLoss: 0.579475\n",
      "Train Epoch: 8 [29000/60000] (48%)\tLoss: 0.242281\n",
      "Train Epoch: 8 [29500/60000] (49%)\tLoss: 0.262670\n",
      "Train Epoch: 8 [30000/60000] (50%)\tLoss: 0.268410\n",
      "Train Epoch: 8 [30500/60000] (51%)\tLoss: 0.261125\n",
      "Train Epoch: 8 [31000/60000] (52%)\tLoss: 0.167702\n",
      "Train Epoch: 8 [31500/60000] (52%)\tLoss: 0.331140\n",
      "Train Epoch: 8 [32000/60000] (53%)\tLoss: 0.440733\n",
      "Train Epoch: 8 [32500/60000] (54%)\tLoss: 0.242829\n",
      "Train Epoch: 8 [33000/60000] (55%)\tLoss: 0.221627\n",
      "Train Epoch: 8 [33500/60000] (56%)\tLoss: 0.267052\n",
      "Train Epoch: 8 [34000/60000] (57%)\tLoss: 0.258132\n",
      "Train Epoch: 8 [34500/60000] (58%)\tLoss: 0.184063\n",
      "Train Epoch: 8 [35000/60000] (58%)\tLoss: 0.352548\n",
      "Train Epoch: 8 [35500/60000] (59%)\tLoss: 0.280561\n",
      "Train Epoch: 8 [36000/60000] (60%)\tLoss: 0.195105\n",
      "Train Epoch: 8 [36500/60000] (61%)\tLoss: 0.224748\n",
      "Train Epoch: 8 [37000/60000] (62%)\tLoss: 0.134481\n",
      "Train Epoch: 8 [37500/60000] (62%)\tLoss: 0.207275\n",
      "Train Epoch: 8 [38000/60000] (63%)\tLoss: 0.212584\n",
      "Train Epoch: 8 [38500/60000] (64%)\tLoss: 0.331615\n",
      "Train Epoch: 8 [39000/60000] (65%)\tLoss: 0.274216\n",
      "Train Epoch: 8 [39500/60000] (66%)\tLoss: 0.220007\n",
      "Train Epoch: 8 [40000/60000] (67%)\tLoss: 0.121164\n",
      "Train Epoch: 8 [40500/60000] (68%)\tLoss: 0.235811\n",
      "Train Epoch: 8 [41000/60000] (68%)\tLoss: 0.554363\n",
      "Train Epoch: 8 [41500/60000] (69%)\tLoss: 0.436887\n",
      "Train Epoch: 8 [42000/60000] (70%)\tLoss: 0.466022\n",
      "Train Epoch: 8 [42500/60000] (71%)\tLoss: 0.106854\n",
      "Train Epoch: 8 [43000/60000] (72%)\tLoss: 0.484230\n",
      "Train Epoch: 8 [43500/60000] (72%)\tLoss: 0.151484\n",
      "Train Epoch: 8 [44000/60000] (73%)\tLoss: 0.265148\n",
      "Train Epoch: 8 [44500/60000] (74%)\tLoss: 0.469579\n",
      "Train Epoch: 8 [45000/60000] (75%)\tLoss: 0.321941\n",
      "Train Epoch: 8 [45500/60000] (76%)\tLoss: 0.257890\n",
      "Train Epoch: 8 [46000/60000] (77%)\tLoss: 0.143811\n",
      "Train Epoch: 8 [46500/60000] (78%)\tLoss: 0.306065\n",
      "Train Epoch: 8 [47000/60000] (78%)\tLoss: 0.338773\n",
      "Train Epoch: 8 [47500/60000] (79%)\tLoss: 0.202137\n",
      "Train Epoch: 8 [48000/60000] (80%)\tLoss: 0.306825\n",
      "Train Epoch: 8 [48500/60000] (81%)\tLoss: 0.499489\n",
      "Train Epoch: 8 [49000/60000] (82%)\tLoss: 0.296580\n",
      "Train Epoch: 8 [49500/60000] (82%)\tLoss: 0.146798\n",
      "Train Epoch: 8 [50000/60000] (83%)\tLoss: 0.376627\n",
      "Train Epoch: 8 [50500/60000] (84%)\tLoss: 0.433875\n",
      "Train Epoch: 8 [51000/60000] (85%)\tLoss: 0.218725\n",
      "Train Epoch: 8 [51500/60000] (86%)\tLoss: 0.333058\n",
      "Train Epoch: 8 [52000/60000] (87%)\tLoss: 0.222742\n",
      "Train Epoch: 8 [52500/60000] (88%)\tLoss: 0.248160\n",
      "Train Epoch: 8 [53000/60000] (88%)\tLoss: 0.366241\n",
      "Train Epoch: 8 [53500/60000] (89%)\tLoss: 0.334488\n",
      "Train Epoch: 8 [54000/60000] (90%)\tLoss: 0.233420\n",
      "Train Epoch: 8 [54500/60000] (91%)\tLoss: 0.347431\n",
      "Train Epoch: 8 [55000/60000] (92%)\tLoss: 0.292022\n",
      "Train Epoch: 8 [55500/60000] (92%)\tLoss: 0.380717\n",
      "Train Epoch: 8 [56000/60000] (93%)\tLoss: 0.302465\n",
      "Train Epoch: 8 [56500/60000] (94%)\tLoss: 0.339405\n",
      "Train Epoch: 8 [57000/60000] (95%)\tLoss: 0.246804\n",
      "Train Epoch: 8 [57500/60000] (96%)\tLoss: 0.366149\n",
      "Train Epoch: 8 [58000/60000] (97%)\tLoss: 0.321692\n",
      "Train Epoch: 8 [58500/60000] (98%)\tLoss: 0.240602\n",
      "Train Epoch: 8 [59000/60000] (98%)\tLoss: 0.344829\n",
      "Train Epoch: 8 [59500/60000] (99%)\tLoss: 0.120199\n",
      "\n",
      "Test Set: Avg. Loss: 0.1107, Accuracy: 9656/10000 (97%)\n",
      "\n",
      "Train Epoch: 9 [0/60000] (0%)\tLoss: 0.300815\n",
      "Train Epoch: 9 [500/60000] (1%)\tLoss: 0.221640\n",
      "Train Epoch: 9 [1000/60000] (2%)\tLoss: 0.286210\n",
      "Train Epoch: 9 [1500/60000] (2%)\tLoss: 0.258386\n",
      "Train Epoch: 9 [2000/60000] (3%)\tLoss: 0.266956\n",
      "Train Epoch: 9 [2500/60000] (4%)\tLoss: 0.192320\n",
      "Train Epoch: 9 [3000/60000] (5%)\tLoss: 0.450267\n",
      "Train Epoch: 9 [3500/60000] (6%)\tLoss: 0.458611\n",
      "Train Epoch: 9 [4000/60000] (7%)\tLoss: 0.282422\n",
      "Train Epoch: 9 [4500/60000] (8%)\tLoss: 0.289073\n",
      "Train Epoch: 9 [5000/60000] (8%)\tLoss: 0.425164\n",
      "Train Epoch: 9 [5500/60000] (9%)\tLoss: 0.141643\n",
      "Train Epoch: 9 [6000/60000] (10%)\tLoss: 0.217224\n",
      "Train Epoch: 9 [6500/60000] (11%)\tLoss: 0.287613\n",
      "Train Epoch: 9 [7000/60000] (12%)\tLoss: 0.302266\n",
      "Train Epoch: 9 [7500/60000] (12%)\tLoss: 0.574255\n",
      "Train Epoch: 9 [8000/60000] (13%)\tLoss: 0.423878\n",
      "Train Epoch: 9 [8500/60000] (14%)\tLoss: 0.376317\n",
      "Train Epoch: 9 [9000/60000] (15%)\tLoss: 0.342299\n",
      "Train Epoch: 9 [9500/60000] (16%)\tLoss: 0.366053\n",
      "Train Epoch: 9 [10000/60000] (17%)\tLoss: 0.131196\n",
      "Train Epoch: 9 [10500/60000] (18%)\tLoss: 0.228871\n",
      "Train Epoch: 9 [11000/60000] (18%)\tLoss: 0.269329\n",
      "Train Epoch: 9 [11500/60000] (19%)\tLoss: 0.217127\n",
      "Train Epoch: 9 [12000/60000] (20%)\tLoss: 0.221988\n",
      "Train Epoch: 9 [12500/60000] (21%)\tLoss: 0.317681\n",
      "Train Epoch: 9 [13000/60000] (22%)\tLoss: 0.424955\n",
      "Train Epoch: 9 [13500/60000] (22%)\tLoss: 0.209299\n",
      "Train Epoch: 9 [14000/60000] (23%)\tLoss: 0.439299\n",
      "Train Epoch: 9 [14500/60000] (24%)\tLoss: 0.285544\n",
      "Train Epoch: 9 [15000/60000] (25%)\tLoss: 0.147753\n",
      "Train Epoch: 9 [15500/60000] (26%)\tLoss: 0.459177\n",
      "Train Epoch: 9 [16000/60000] (27%)\tLoss: 0.290293\n",
      "Train Epoch: 9 [16500/60000] (28%)\tLoss: 0.251973\n",
      "Train Epoch: 9 [17000/60000] (28%)\tLoss: 0.345815\n",
      "Train Epoch: 9 [17500/60000] (29%)\tLoss: 0.254964\n",
      "Train Epoch: 9 [18000/60000] (30%)\tLoss: 0.232166\n",
      "Train Epoch: 9 [18500/60000] (31%)\tLoss: 0.244319\n",
      "Train Epoch: 9 [19000/60000] (32%)\tLoss: 0.161908\n",
      "Train Epoch: 9 [19500/60000] (32%)\tLoss: 0.166602\n",
      "Train Epoch: 9 [20000/60000] (33%)\tLoss: 0.668706\n",
      "Train Epoch: 9 [20500/60000] (34%)\tLoss: 0.299172\n",
      "Train Epoch: 9 [21000/60000] (35%)\tLoss: 0.371181\n",
      "Train Epoch: 9 [21500/60000] (36%)\tLoss: 0.318544\n",
      "Train Epoch: 9 [22000/60000] (37%)\tLoss: 0.442612\n",
      "Train Epoch: 9 [22500/60000] (38%)\tLoss: 0.501268\n",
      "Train Epoch: 9 [23000/60000] (38%)\tLoss: 0.129885\n",
      "Train Epoch: 9 [23500/60000] (39%)\tLoss: 0.296030\n",
      "Train Epoch: 9 [24000/60000] (40%)\tLoss: 0.332395\n",
      "Train Epoch: 9 [24500/60000] (41%)\tLoss: 0.197581\n",
      "Train Epoch: 9 [25000/60000] (42%)\tLoss: 0.237618\n",
      "Train Epoch: 9 [25500/60000] (42%)\tLoss: 0.186461\n",
      "Train Epoch: 9 [26000/60000] (43%)\tLoss: 0.176611\n",
      "Train Epoch: 9 [26500/60000] (44%)\tLoss: 0.456050\n",
      "Train Epoch: 9 [27000/60000] (45%)\tLoss: 0.499311\n",
      "Train Epoch: 9 [27500/60000] (46%)\tLoss: 0.263908\n",
      "Train Epoch: 9 [28000/60000] (47%)\tLoss: 0.372635\n",
      "Train Epoch: 9 [28500/60000] (48%)\tLoss: 0.290776\n",
      "Train Epoch: 9 [29000/60000] (48%)\tLoss: 0.492920\n",
      "Train Epoch: 9 [29500/60000] (49%)\tLoss: 0.595267\n",
      "Train Epoch: 9 [30000/60000] (50%)\tLoss: 0.389118\n",
      "Train Epoch: 9 [30500/60000] (51%)\tLoss: 0.421583\n",
      "Train Epoch: 9 [31000/60000] (52%)\tLoss: 0.390462\n",
      "Train Epoch: 9 [31500/60000] (52%)\tLoss: 0.386193\n",
      "Train Epoch: 9 [32000/60000] (53%)\tLoss: 0.170363\n",
      "Train Epoch: 9 [32500/60000] (54%)\tLoss: 0.159781\n",
      "Train Epoch: 9 [33000/60000] (55%)\tLoss: 0.327225\n",
      "Train Epoch: 9 [33500/60000] (56%)\tLoss: 0.118384\n",
      "Train Epoch: 9 [34000/60000] (57%)\tLoss: 0.294179\n",
      "Train Epoch: 9 [34500/60000] (58%)\tLoss: 0.253995\n",
      "Train Epoch: 9 [35000/60000] (58%)\tLoss: 0.258691\n",
      "Train Epoch: 9 [35500/60000] (59%)\tLoss: 0.333489\n",
      "Train Epoch: 9 [36000/60000] (60%)\tLoss: 0.340945\n",
      "Train Epoch: 9 [36500/60000] (61%)\tLoss: 0.304798\n",
      "Train Epoch: 9 [37000/60000] (62%)\tLoss: 0.279918\n",
      "Train Epoch: 9 [37500/60000] (62%)\tLoss: 0.360438\n",
      "Train Epoch: 9 [38000/60000] (63%)\tLoss: 0.219112\n",
      "Train Epoch: 9 [38500/60000] (64%)\tLoss: 0.290570\n",
      "Train Epoch: 9 [39000/60000] (65%)\tLoss: 0.117918\n",
      "Train Epoch: 9 [39500/60000] (66%)\tLoss: 0.136660\n",
      "Train Epoch: 9 [40000/60000] (67%)\tLoss: 0.100789\n",
      "Train Epoch: 9 [40500/60000] (68%)\tLoss: 0.258331\n",
      "Train Epoch: 9 [41000/60000] (68%)\tLoss: 0.151872\n",
      "Train Epoch: 9 [41500/60000] (69%)\tLoss: 0.437412\n",
      "Train Epoch: 9 [42000/60000] (70%)\tLoss: 0.299672\n",
      "Train Epoch: 9 [42500/60000] (71%)\tLoss: 0.261002\n",
      "Train Epoch: 9 [43000/60000] (72%)\tLoss: 0.494920\n",
      "Train Epoch: 9 [43500/60000] (72%)\tLoss: 0.165806\n",
      "Train Epoch: 9 [44000/60000] (73%)\tLoss: 0.297222\n",
      "Train Epoch: 9 [44500/60000] (74%)\tLoss: 0.270114\n",
      "Train Epoch: 9 [45000/60000] (75%)\tLoss: 0.320684\n",
      "Train Epoch: 9 [45500/60000] (76%)\tLoss: 0.145107\n",
      "Train Epoch: 9 [46000/60000] (77%)\tLoss: 0.264695\n",
      "Train Epoch: 9 [46500/60000] (78%)\tLoss: 0.322856\n",
      "Train Epoch: 9 [47000/60000] (78%)\tLoss: 0.234856\n",
      "Train Epoch: 9 [47500/60000] (79%)\tLoss: 0.237765\n",
      "Train Epoch: 9 [48000/60000] (80%)\tLoss: 0.205016\n",
      "Train Epoch: 9 [48500/60000] (81%)\tLoss: 0.489919\n",
      "Train Epoch: 9 [49000/60000] (82%)\tLoss: 0.459513\n",
      "Train Epoch: 9 [49500/60000] (82%)\tLoss: 0.317047\n",
      "Train Epoch: 9 [50000/60000] (83%)\tLoss: 0.183547\n",
      "Train Epoch: 9 [50500/60000] (84%)\tLoss: 0.462917\n",
      "Train Epoch: 9 [51000/60000] (85%)\tLoss: 0.286486\n",
      "Train Epoch: 9 [51500/60000] (86%)\tLoss: 0.293491\n",
      "Train Epoch: 9 [52000/60000] (87%)\tLoss: 0.458904\n",
      "Train Epoch: 9 [52500/60000] (88%)\tLoss: 0.212501\n",
      "Train Epoch: 9 [53000/60000] (88%)\tLoss: 0.317091\n",
      "Train Epoch: 9 [53500/60000] (89%)\tLoss: 0.216183\n",
      "Train Epoch: 9 [54000/60000] (90%)\tLoss: 0.238454\n",
      "Train Epoch: 9 [54500/60000] (91%)\tLoss: 0.185722\n",
      "Train Epoch: 9 [55000/60000] (92%)\tLoss: 0.237316\n",
      "Train Epoch: 9 [55500/60000] (92%)\tLoss: 0.185865\n",
      "Train Epoch: 9 [56000/60000] (93%)\tLoss: 0.186425\n",
      "Train Epoch: 9 [56500/60000] (94%)\tLoss: 0.249524\n",
      "Train Epoch: 9 [57000/60000] (95%)\tLoss: 0.180140\n",
      "Train Epoch: 9 [57500/60000] (96%)\tLoss: 0.356958\n",
      "Train Epoch: 9 [58000/60000] (97%)\tLoss: 0.181772\n",
      "Train Epoch: 9 [58500/60000] (98%)\tLoss: 0.223472\n",
      "Train Epoch: 9 [59000/60000] (98%)\tLoss: 0.236190\n",
      "Train Epoch: 9 [59500/60000] (99%)\tLoss: 0.238739\n",
      "\n",
      "Test Set: Avg. Loss: 0.1084, Accuracy: 9653/10000 (97%)\n",
      "\n",
      "Train Epoch: 10 [0/60000] (0%)\tLoss: 0.318122\n",
      "Train Epoch: 10 [500/60000] (1%)\tLoss: 0.170651\n",
      "Train Epoch: 10 [1000/60000] (2%)\tLoss: 0.344825\n",
      "Train Epoch: 10 [1500/60000] (2%)\tLoss: 0.232146\n",
      "Train Epoch: 10 [2000/60000] (3%)\tLoss: 0.119124\n",
      "Train Epoch: 10 [2500/60000] (4%)\tLoss: 0.154260\n",
      "Train Epoch: 10 [3000/60000] (5%)\tLoss: 0.285063\n",
      "Train Epoch: 10 [3500/60000] (6%)\tLoss: 0.271669\n",
      "Train Epoch: 10 [4000/60000] (7%)\tLoss: 0.229859\n",
      "Train Epoch: 10 [4500/60000] (8%)\tLoss: 0.308859\n",
      "Train Epoch: 10 [5000/60000] (8%)\tLoss: 0.239564\n",
      "Train Epoch: 10 [5500/60000] (9%)\tLoss: 0.321490\n",
      "Train Epoch: 10 [6000/60000] (10%)\tLoss: 0.160916\n",
      "Train Epoch: 10 [6500/60000] (11%)\tLoss: 0.336028\n",
      "Train Epoch: 10 [7000/60000] (12%)\tLoss: 0.455605\n",
      "Train Epoch: 10 [7500/60000] (12%)\tLoss: 0.259883\n",
      "Train Epoch: 10 [8000/60000] (13%)\tLoss: 0.205554\n",
      "Train Epoch: 10 [8500/60000] (14%)\tLoss: 0.643340\n",
      "Train Epoch: 10 [9000/60000] (15%)\tLoss: 0.404183\n",
      "Train Epoch: 10 [9500/60000] (16%)\tLoss: 0.195965\n",
      "Train Epoch: 10 [10000/60000] (17%)\tLoss: 0.572554\n",
      "Train Epoch: 10 [10500/60000] (18%)\tLoss: 0.237216\n",
      "Train Epoch: 10 [11000/60000] (18%)\tLoss: 0.238200\n",
      "Train Epoch: 10 [11500/60000] (19%)\tLoss: 0.283576\n",
      "Train Epoch: 10 [12000/60000] (20%)\tLoss: 0.351545\n",
      "Train Epoch: 10 [12500/60000] (21%)\tLoss: 0.248823\n",
      "Train Epoch: 10 [13000/60000] (22%)\tLoss: 0.231771\n",
      "Train Epoch: 10 [13500/60000] (22%)\tLoss: 0.246457\n",
      "Train Epoch: 10 [14000/60000] (23%)\tLoss: 0.289305\n",
      "Train Epoch: 10 [14500/60000] (24%)\tLoss: 0.182162\n",
      "Train Epoch: 10 [15000/60000] (25%)\tLoss: 0.226919\n",
      "Train Epoch: 10 [15500/60000] (26%)\tLoss: 0.130407\n",
      "Train Epoch: 10 [16000/60000] (27%)\tLoss: 0.180456\n",
      "Train Epoch: 10 [16500/60000] (28%)\tLoss: 0.636545\n",
      "Train Epoch: 10 [17000/60000] (28%)\tLoss: 0.340614\n",
      "Train Epoch: 10 [17500/60000] (29%)\tLoss: 0.309010\n",
      "Train Epoch: 10 [18000/60000] (30%)\tLoss: 0.119771\n",
      "Train Epoch: 10 [18500/60000] (31%)\tLoss: 0.310333\n",
      "Train Epoch: 10 [19000/60000] (32%)\tLoss: 0.353055\n",
      "Train Epoch: 10 [19500/60000] (32%)\tLoss: 0.222644\n",
      "Train Epoch: 10 [20000/60000] (33%)\tLoss: 0.228223\n",
      "Train Epoch: 10 [20500/60000] (34%)\tLoss: 0.518494\n",
      "Train Epoch: 10 [21000/60000] (35%)\tLoss: 0.460779\n",
      "Train Epoch: 10 [21500/60000] (36%)\tLoss: 0.422359\n",
      "Train Epoch: 10 [22000/60000] (37%)\tLoss: 0.172870\n",
      "Train Epoch: 10 [22500/60000] (38%)\tLoss: 0.123784\n",
      "Train Epoch: 10 [23000/60000] (38%)\tLoss: 0.270765\n",
      "Train Epoch: 10 [23500/60000] (39%)\tLoss: 0.188049\n",
      "Train Epoch: 10 [24000/60000] (40%)\tLoss: 0.125726\n",
      "Train Epoch: 10 [24500/60000] (41%)\tLoss: 0.229515\n",
      "Train Epoch: 10 [25000/60000] (42%)\tLoss: 0.187680\n",
      "Train Epoch: 10 [25500/60000] (42%)\tLoss: 0.313890\n",
      "Train Epoch: 10 [26000/60000] (43%)\tLoss: 0.114524\n",
      "Train Epoch: 10 [26500/60000] (44%)\tLoss: 0.178297\n",
      "Train Epoch: 10 [27000/60000] (45%)\tLoss: 0.166150\n",
      "Train Epoch: 10 [27500/60000] (46%)\tLoss: 0.153365\n",
      "Train Epoch: 10 [28000/60000] (47%)\tLoss: 0.488523\n",
      "Train Epoch: 10 [28500/60000] (48%)\tLoss: 0.410506\n",
      "Train Epoch: 10 [29000/60000] (48%)\tLoss: 0.464245\n",
      "Train Epoch: 10 [29500/60000] (49%)\tLoss: 0.569144\n",
      "Train Epoch: 10 [30000/60000] (50%)\tLoss: 0.255120\n",
      "Train Epoch: 10 [30500/60000] (51%)\tLoss: 0.246137\n",
      "Train Epoch: 10 [31000/60000] (52%)\tLoss: 0.323620\n",
      "Train Epoch: 10 [31500/60000] (52%)\tLoss: 0.233612\n",
      "Train Epoch: 10 [32000/60000] (53%)\tLoss: 0.477523\n",
      "Train Epoch: 10 [32500/60000] (54%)\tLoss: 0.595361\n",
      "Train Epoch: 10 [33000/60000] (55%)\tLoss: 0.218536\n",
      "Train Epoch: 10 [33500/60000] (56%)\tLoss: 0.259560\n",
      "Train Epoch: 10 [34000/60000] (57%)\tLoss: 0.207893\n",
      "Train Epoch: 10 [34500/60000] (58%)\tLoss: 0.499206\n",
      "Train Epoch: 10 [35000/60000] (58%)\tLoss: 0.204057\n",
      "Train Epoch: 10 [35500/60000] (59%)\tLoss: 0.161253\n",
      "Train Epoch: 10 [36000/60000] (60%)\tLoss: 0.257606\n",
      "Train Epoch: 10 [36500/60000] (61%)\tLoss: 0.305099\n",
      "Train Epoch: 10 [37000/60000] (62%)\tLoss: 0.217958\n",
      "Train Epoch: 10 [37500/60000] (62%)\tLoss: 0.198655\n",
      "Train Epoch: 10 [38000/60000] (63%)\tLoss: 0.395840\n",
      "Train Epoch: 10 [38500/60000] (64%)\tLoss: 0.391278\n",
      "Train Epoch: 10 [39000/60000] (65%)\tLoss: 0.232878\n",
      "Train Epoch: 10 [39500/60000] (66%)\tLoss: 0.290016\n",
      "Train Epoch: 10 [40000/60000] (67%)\tLoss: 0.314323\n",
      "Train Epoch: 10 [40500/60000] (68%)\tLoss: 0.226559\n",
      "Train Epoch: 10 [41000/60000] (68%)\tLoss: 0.298779\n",
      "Train Epoch: 10 [41500/60000] (69%)\tLoss: 0.225796\n",
      "Train Epoch: 10 [42000/60000] (70%)\tLoss: 0.270374\n",
      "Train Epoch: 10 [42500/60000] (71%)\tLoss: 0.174495\n",
      "Train Epoch: 10 [43000/60000] (72%)\tLoss: 0.178535\n",
      "Train Epoch: 10 [43500/60000] (72%)\tLoss: 0.341962\n",
      "Train Epoch: 10 [44000/60000] (73%)\tLoss: 0.238539\n",
      "Train Epoch: 10 [44500/60000] (74%)\tLoss: 0.448686\n",
      "Train Epoch: 10 [45000/60000] (75%)\tLoss: 0.452206\n",
      "Train Epoch: 10 [45500/60000] (76%)\tLoss: 0.348204\n",
      "Train Epoch: 10 [46000/60000] (77%)\tLoss: 0.170698\n",
      "Train Epoch: 10 [46500/60000] (78%)\tLoss: 0.446323\n",
      "Train Epoch: 10 [47000/60000] (78%)\tLoss: 0.780817\n",
      "Train Epoch: 10 [47500/60000] (79%)\tLoss: 0.514555\n",
      "Train Epoch: 10 [48000/60000] (80%)\tLoss: 0.336845\n",
      "Train Epoch: 10 [48500/60000] (81%)\tLoss: 0.237702\n",
      "Train Epoch: 10 [49000/60000] (82%)\tLoss: 0.355266\n",
      "Train Epoch: 10 [49500/60000] (82%)\tLoss: 0.386486\n",
      "Train Epoch: 10 [50000/60000] (83%)\tLoss: 0.285754\n",
      "Train Epoch: 10 [50500/60000] (84%)\tLoss: 0.313211\n",
      "Train Epoch: 10 [51000/60000] (85%)\tLoss: 0.223163\n",
      "Train Epoch: 10 [51500/60000] (86%)\tLoss: 0.290039\n",
      "Train Epoch: 10 [52000/60000] (87%)\tLoss: 0.461859\n",
      "Train Epoch: 10 [52500/60000] (88%)\tLoss: 0.222285\n",
      "Train Epoch: 10 [53000/60000] (88%)\tLoss: 0.376511\n",
      "Train Epoch: 10 [53500/60000] (89%)\tLoss: 0.522193\n",
      "Train Epoch: 10 [54000/60000] (90%)\tLoss: 0.409974\n",
      "Train Epoch: 10 [54500/60000] (91%)\tLoss: 0.284243\n",
      "Train Epoch: 10 [55000/60000] (92%)\tLoss: 0.185051\n",
      "Train Epoch: 10 [55500/60000] (92%)\tLoss: 0.238167\n",
      "Train Epoch: 10 [56000/60000] (93%)\tLoss: 0.169179\n",
      "Train Epoch: 10 [56500/60000] (94%)\tLoss: 0.216352\n",
      "Train Epoch: 10 [57000/60000] (95%)\tLoss: 0.345710\n",
      "Train Epoch: 10 [57500/60000] (96%)\tLoss: 0.172408\n",
      "Train Epoch: 10 [58000/60000] (97%)\tLoss: 0.318015\n",
      "Train Epoch: 10 [58500/60000] (98%)\tLoss: 0.346739\n",
      "Train Epoch: 10 [59000/60000] (98%)\tLoss: 0.453091\n",
      "Train Epoch: 10 [59500/60000] (99%)\tLoss: 0.366525\n",
      "\n",
      "Test Set: Avg. Loss: 0.1072, Accuracy: 9666/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test(dataloader=test_loader)\n",
    "for epoch in range(0, epochs):\n",
    "     train(epoch=epoch+1, dataloader=train_loader, optimizer=optimizer)\n",
    "     test(dataloader=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rdash\\AppData\\Local\\Temp\\ipykernel_10888\\3801493435.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set: Avg. Loss: 0.2304, Accuracy: 9318/10000 (93%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(train_count, train_loss, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mred\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Loss\u001b[39m\u001b[38;5;124m'\u001b[39m], loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupper right\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber of training examples seen\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rdash\\anaconda3\\envs\\nn\\Lib\\site-packages\\matplotlib\\pyplot.py:3687\u001b[0m, in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[0;32m   3668\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mscatter)\n\u001b[0;32m   3669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscatter\u001b[39m(\n\u001b[0;32m   3670\u001b[0m     x: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3685\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3686\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PathCollection:\n\u001b[1;32m-> 3687\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3689\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3690\u001b[0m \u001b[43m        \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmarker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmarker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3697\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinewidths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinewidths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3699\u001b[0m \u001b[43m        \u001b[49m\u001b[43medgecolors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplotnonfinite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplotnonfinite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3701\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3702\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3704\u001b[0m     sci(__ret)\n\u001b[0;32m   3705\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[1;32mc:\\Users\\rdash\\anaconda3\\envs\\nn\\Lib\\site-packages\\matplotlib\\__init__.py:1465\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1462\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1467\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1468\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1469\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32mc:\\Users\\rdash\\anaconda3\\envs\\nn\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:4652\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   4650\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mravel(y)\n\u001b[0;32m   4651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39msize:\n\u001b[1;32m-> 4652\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must be the same size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4655\u001b[0m     s \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_internal.classic_mode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[0;32m   4656\u001b[0m          mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlines.markersize\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2.0\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_count, train_loss, color='blue')\n",
    "plt.scatter(test_count, test_loss, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  output = model(example_data)\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Prediction: {}\".format(\n",
    "    output.data.max(1, keepdim=True)[1][i].item()))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
